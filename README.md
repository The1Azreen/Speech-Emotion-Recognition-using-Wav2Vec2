(Archived)
# Speech-Emotion-Recognition-using-Wav2Vec2

## Project Overview
This project implements a Speech Emotion Recognition (SER) system using the Wav2Vec2 pre-trained model. The system analyzes speech audio and classifies it into four emotional categories: Neutral, Happy, Sad, and Angry. This implementation is based on the paper "3-D Convolutional Recurrent Neural Networks With Attention Model for Speech Emotion Recognition" but with significant modifications to use modern transformer-based architectures.

## Problem Statement
Speech Emotion Recognition is a challenging task in audio processing that requires understanding subtle variations in speech patterns, tone, and acoustic features. Traditional approaches often struggle with:
- Capturing temporal dependencies in speech
- Handling variable-length inputs
- Generalizing across different speakers
- Dealing with limited labeled data

## Getting Started

### Prerequisites
- Python 3
- pip
- CUDA capable GPU i.e. T4 or A100 (Google Colab) or any other GPU (Local Machine)

