{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9564979,
          "sourceType": "datasetVersion",
          "datasetId": 5829354
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2302700 - Muhd Hafiz bin Abdul Halim\n",
        "\n",
        "2200581 - Muhammad Azreen Bin Muhamamad"
      ],
      "metadata": {
        "id": "0NIMJtGLc5ZF"
      },
      "id": "0NIMJtGLc5ZF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Best results are achieved under:\n",
        "++++++++++++++++++++++\n",
        "\n",
        "Feature Extractor/Preprocess the dataset=True\n",
        "\n",
        "Data Augmentation=False\n",
        "\n",
        "Use-pre-trained-model=True\n",
        "\n",
        "Finetune=True\n",
        "\n",
        "Optimizer=adamW\n",
        "\n",
        "Hyperparameters=True\n",
        "\n",
        "EarlyStopping=True\n",
        "\n",
        "Different NN=False\n",
        "\n",
        "Pooling Layer-=False\n",
        "\n",
        "++++++++++++++++++++++"
      ],
      "metadata": {
        "id": "kQu8wqFsP2JH"
      },
      "id": "kQu8wqFsP2JH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Phase\n"
      ],
      "metadata": {
        "id": "iVbmV5qhALcV"
      },
      "id": "iVbmV5qhALcV"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UY13IJ8EdLei"
      },
      "id": "UY13IJ8EdLei"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check if your using Nvidia GPU\n",
        "### Amd gpu works too via ROCM on pytorch linux\n",
        "### Install dataset as both colab and kaggle does not contain it at runtime"
      ],
      "metadata": {
        "id": "wks64T_yGt7x"
      },
      "id": "wks64T_yGt7x"
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi #make sure you choose GPU, the default type is CPU, click change runtime type, set hardware accelerator to *GPU"
      ],
      "metadata": {
        "id": "UF0qVkFglRjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8340f093-8c61-4c50-8fb1-eb4799ea7bde",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:50:44.170047Z",
          "iopub.execute_input": "2024-10-08T23:50:44.170555Z",
          "iopub.status.idle": "2024-10-08T23:50:45.267926Z",
          "shell.execute_reply.started": "2024-10-08T23:50:44.170507Z",
          "shell.execute_reply": "2024-10-08T23:50:45.266582Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Tue Oct  8 23:50:45 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   42C    P0             27W /  250W |       0MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ],
      "id": "UF0qVkFglRjk"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o small-project.zip -d small-project"
      ],
      "metadata": {
        "id": "Ms7kMXDT49TJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e2c2bb-51fc-46d2-b9db-fbed9fcbf61d",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:50:45.270470Z",
          "iopub.execute_input": "2024-10-08T23:50:45.270894Z",
          "iopub.status.idle": "2024-10-08T23:50:46.508231Z",
          "shell.execute_reply.started": "2024-10-08T23:50:45.270848Z",
          "shell.execute_reply": "2024-10-08T23:50:46.506781Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "unzip:  cannot find or open small-project.zip, small-project.zip.zip or small-project.zip.ZIP.\n",
          "output_type": "stream"
        }
      ],
      "id": "Ms7kMXDT49TJ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "Xy8_g_wRlQ_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b38d4b-7e9d-48fd-cfaa-6b53c185e9ce",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:50:46.510804Z",
          "iopub.execute_input": "2024-10-08T23:50:46.511510Z",
          "iopub.status.idle": "2024-10-08T23:50:59.825629Z",
          "shell.execute_reply.started": "2024-10-08T23:50:46.511437Z",
          "shell.execute_reply": "2024-10-08T23:50:59.824481Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.22.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.25.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
          "output_type": "stream"
        }
      ],
      "id": "Xy8_g_wRlQ_w"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Puts input files into seperate folders"
      ],
      "metadata": {
        "id": "_kQ4HPevbYH0"
      },
      "id": "_kQ4HPevbYH0"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "df_all = pd.read_csv('small-project/small-project/IEMOCAP_4.tsv',sep='\\t')\n",
        "speakers = np.unique(data_all['speaker']) # only 10 speakers, (['Ses01F', 'Ses01M', 'Ses02F', 'Ses02M', 'Ses03F', 'Ses03M','Ses04F', 'Ses04M', 'Ses05F', 'Ses05M']\n",
        "spk_len = len(speakers)\n",
        "spk_len\n",
        "\n",
        "test_idx = np.array(df_all['speaker']==speakers[0]) # audio from 'Ses01F' as test set\n",
        "val_idx = np.array(df_all['speaker']==speakers[1]) #  audio from 'Ses01M' as val set\n",
        "train_idx = True^(test_idx+val_idx)\n",
        "train_data_info = df_all[train_idx].reset_index(drop=True)\n",
        "val_data_info = df_all[val_idx].reset_index(drop=True)\n",
        "test_data_info = df_all[test_idx].reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "LJW2k56DbPBI"
      },
      "id": "LJW2k56DbPBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "og_path = \"small-project\\small-project\\IEMOCAP_full_release_audio\"\n",
        "\n",
        "TRAIN = os.path.join(\"\", 'train')\n",
        "os.makedirs(TRAIN, exist_ok=True)\n",
        "TEST = os.path.join(\"\", 'test')\n",
        "os.makedirs(TEST, exist_ok=True)\n",
        "VAL = os.path.join(\"\", 'val')\n",
        "os.makedirs(VAL, exist_ok=True)\n",
        "\n",
        "for row in train_data_info['filename']:\n",
        "    original_filepath = os.path.join(og_path, f\"{row}.wav\")\n",
        "    new_filepath = os.path.join(TRAIN, f\"{row}.wav\")\n",
        "    # Copy the file to the destination folder\n",
        "    shutil.copy(original_filepath, new_filepath)\n",
        "\n",
        "for row in test_data_info['filename']:\n",
        "    original_filepath = os.path.join(og_path, f\"{row}.wav\")\n",
        "    new_filepath = os.path.join(TEST, f\"{row}.wav\")\n",
        "    # Copy the file to the destination folder\n",
        "    shutil.copy(original_filepath, new_filepath)\n",
        "\n",
        "\n",
        "for row in val_data_info['filename']:\n",
        "    original_filepath = os.path.join(og_path, f\"{row}.wav\")\n",
        "    new_filepath = os.path.join(VAL, f\"{row}.wav\")\n",
        "    # Copy the file to the destination folder\n",
        "    shutil.copy(original_filepath, new_filepath)"
      ],
      "metadata": {
        "id": "NR6WiBC4b8B7"
      },
      "id": "NR6WiBC4b8B7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Package and Ultilty Function\n"
      ],
      "metadata": {
        "id": "QrN3WCcJGyWs"
      },
      "id": "QrN3WCcJGyWs"
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define the seed setup function\n",
        "def setup_seed(seed=2042):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-08T23:50:59.829027Z",
          "iopub.execute_input": "2024-10-08T23:50:59.829492Z",
          "iopub.status.idle": "2024-10-08T23:50:59.837479Z",
          "shell.execute_reply.started": "2024-10-08T23:50:59.829421Z",
          "shell.execute_reply": "2024-10-08T23:50:59.836470Z"
        },
        "trusted": true,
        "id": "RhTfauETGdWE"
      },
      "execution_count": null,
      "outputs": [],
      "id": "RhTfauETGdWE"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "\n",
        "# Path to your dataset and CSV file\n",
        "TSV = r'/kaggle/input/small-project-dataset/dataset/IEMOCAP_4.tsv' #Change to Collab/Kaggle Directory\n",
        "DATASET = r'/kaggle/input/small-project-dataset/dataset' #Change to Collab/Kaggle Directory\n",
        "TRAIN = os.path.join(DATASET, 'train')\n",
        "TEST = os.path.join(DATASET, 'test')\n",
        "VAL = os.path.join(DATASET, 'val')\n",
        "\n",
        "# Verify filepaths\n",
        "print(\"Train folder path:\", TRAIN)\n",
        "print(\"Test folder path:\", TEST)\n",
        "print(\"Validation folder path:\", VAL)\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"A\": 0, \"H\": 1, \"N\": 2, \"S\": 3}\n",
        "\n",
        "# Parameters\n",
        "max_len = 7\n",
        "epochs = 15\n",
        "seed = 2042\n",
        "\n",
        "# Set the seed for reproducibility\n",
        "setup_seed(seed)"
      ],
      "metadata": {
        "id": "487ad5d5-bea7-44e4-8a8c-8efec0c8d358",
        "execution": {
          "iopub.status.busy": "2024-10-09T01:38:28.952127Z",
          "iopub.execute_input": "2024-10-09T01:38:28.952832Z",
          "iopub.status.idle": "2024-10-09T01:38:28.963617Z",
          "shell.execute_reply.started": "2024-10-09T01:38:28.952784Z",
          "shell.execute_reply": "2024-10-09T01:38:28.962598Z"
        },
        "trusted": true,
        "outputId": "ab5d186a-7566-4f39-cffb-dbb08193c1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Train folder path: /kaggle/input/small-project-dataset/dataset/train\nTest folder path: /kaggle/input/small-project-dataset/dataset/test\nValidation folder path: /kaggle/input/small-project-dataset/dataset/val\n",
          "output_type": "stream"
        }
      ],
      "id": "487ad5d5-bea7-44e4-8a8c-8efec0c8d358"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Helper functions to pre-process the training data from raw Fbank features of each utterance.**\n",
        "\n",
        "The sample rate of speech is 16K (the number of samples per second is 16000)\n",
        "\n",
        "The input length for each utterance is different, cut them to 6s if larger than 6s, copy speech until 6s if less than 6s"
      ],
      "metadata": {
        "id": "m6Xdkof0HKPG"
      },
      "id": "m6Xdkof0HKPG"
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_trunc_wav(x, max_len):\n",
        "    max_len = max_len * 16000  # Convert to number of samples\n",
        "\n",
        "    # Ensure consistent input length\n",
        "    if x.shape[1] < max_len:\n",
        "        # Pad with zeros if shorter\n",
        "        padding = max_len - x.shape[1]\n",
        "        x_new = torch.cat([x, torch.zeros(1, padding)], dim=1)  # Padding on the right\n",
        "    else:\n",
        "        # Truncate if longer\n",
        "        x_new = x[:, :max_len]\n",
        "\n",
        "    return x_new"
      ],
      "metadata": {
        "id": "2UgnXdCScdhZ",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:51:21.005301Z",
          "iopub.execute_input": "2024-10-08T23:51:21.005979Z",
          "iopub.status.idle": "2024-10-08T23:51:21.012069Z",
          "shell.execute_reply.started": "2024-10-08T23:51:21.005942Z",
          "shell.execute_reply": "2024-10-08T23:51:21.011058Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "2UgnXdCScdhZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load TSV file\n",
        "label_df = pd.read_csv(TSV, sep='\\t')\n",
        "\n",
        "def load_audio_file(file_path):\n",
        "    try:\n",
        "        # Load a wav file using torchaudio\n",
        "        speech_array, sampling_rate = torchaudio.load(file_path)\n",
        "        if speech_array.size(1) == 0:  # If no samples are loaded\n",
        "            print(f\"Warning: {file_path} is empty or invalid.\")\n",
        "            return None, None  # Return None for invalid files\n",
        "        return speech_array.squeeze().numpy(), sampling_rate\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {file_path}: {e}\")\n",
        "        return None, None  # Return None for files that raise exceptions\n",
        "\n"
      ],
      "metadata": {
        "id": "INIYpklpci9g",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:51:21.014135Z",
          "iopub.execute_input": "2024-10-08T23:51:21.015865Z",
          "iopub.status.idle": "2024-10-08T23:51:21.063305Z",
          "shell.execute_reply.started": "2024-10-08T23:51:21.015811Z",
          "shell.execute_reply": "2024-10-08T23:51:21.062487Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "INIYpklpci9g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset + truncating + Padding"
      ],
      "metadata": {
        "id": "B2aoGKGtHOL4"
      },
      "id": "B2aoGKGtHOL4"
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(audio_folder, label_df):\n",
        "    data = []\n",
        "\n",
        "    for index, row in label_df.iterrows():\n",
        "        file_name = row[\"filename\"] + \".wav\"  # Ensure filename has .wav extension\n",
        "        label_str = row[\"label\"]  # Original string label from CSV\n",
        "        file_path = os.path.join(audio_folder, file_name)\n",
        "\n",
        "        # Check if the file exists and has a .wav extension\n",
        "        if os.path.exists(file_path) and file_path.endswith(\".wav\"):\n",
        "            speech, sampling_rate = load_audio_file(file_path)\n",
        "\n",
        "            # Apply the pad_trunc_wav function to ensure consistent audio length\n",
        "            speech = torch.tensor(speech).unsqueeze(0)  # Add batch dimension for padding\n",
        "            speech = pad_trunc_wav(speech, max_len=max_len).squeeze(0)  # Remove batch dimension after padding/truncating\n",
        "\n",
        "            # Map the string label to its numerical equivalent using the label mapping\n",
        "            if label_str in label_mapping:\n",
        "                label = label_mapping[label_str]\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown label '{label_str}' encountered.\")\n",
        "\n",
        "            # Append the data dictionary\n",
        "            data.append({\"speech\": speech, \"sampling_rate\": sampling_rate, \"label\": label})\n",
        "\n",
        "    # Create the dataset from the loaded data\n",
        "    return Dataset.from_dict({\n",
        "        \"speech\": [d[\"speech\"] for d in data],\n",
        "        \"sampling_rate\": [d[\"sampling_rate\"] for d in data],\n",
        "        \"label\": [d[\"label\"] for d in data]\n",
        "    })\n",
        "\n",
        "# Load your dataset\n",
        "training = load_dataset(TRAIN, label_df)\n",
        "testing = load_dataset(TEST, label_df)\n",
        "validation = load_dataset(VAL, label_df)\n",
        "print(\"Total Files Loaded:\")\n",
        "print(f\"Training Total Amount: {len(training)}\")\n",
        "print(f\"Testing Total Amount: {len(testing)}\")\n",
        "print(f\"Validation Total Amount: {len(validation)}\")\n",
        "\n",
        "# Define a DatasetDict object\n",
        "emotion_dataset = DatasetDict({\n",
        "    \"train\": training,\n",
        "    \"test\": testing,\n",
        "    \"val\": validation\n",
        "})"
      ],
      "metadata": {
        "id": "O7qHOw-Vcq51",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:51:21.064669Z",
          "iopub.execute_input": "2024-10-08T23:51:21.065021Z",
          "iopub.status.idle": "2024-10-08T23:54:04.158602Z",
          "shell.execute_reply.started": "2024-10-08T23:51:21.064983Z",
          "shell.execute_reply": "2024-10-08T23:54:04.157515Z"
        },
        "trusted": true,
        "outputId": "82c582fd-881b-4c3f-fb23-147eba44e5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Total Files Loaded:\nTraining Total Amount: 4446\nTesting Total Amount: 528\nValidation Total Amount: 557\n",
          "output_type": "stream"
        }
      ],
      "id": "O7qHOw-Vcq51"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Pretrained Model for Feature Extractor + Define the prerocess function\n",
        "Model we are using is Wav2Vec2 facebook baselin variant https://huggingface.co/docs/transformers/en/model_doc/wav2vec2 this is to ensure a fair training process and to fufill the no IEMOCAP pretuned criteria"
      ],
      "metadata": {
        "id": "3wJQ3AH6HT0E"
      },
      "id": "3wJQ3AH6HT0E"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Wav2Vec2 feature extractor and model\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(\n",
        "    \"facebook/wav2vec2-base\",\n",
        "    num_labels=4  # Adjust this to match the number of emotion classes in your dataset\n",
        ")\n",
        "\n",
        "# Preprocess the dataset\n",
        "def preprocess_function(examples):\n",
        "    # Ensure that the inputs are numpy arrays and float32 type\n",
        "    audio_inputs = [speech.astype(np.float32) for speech in examples[\"speech\"]]\n",
        "    # Use the feature extractor to process the audio inputs\n",
        "    inputs = feature_extractor(audio_inputs, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
        "    inputs[\"label\"] = examples[\"label\"]  # Add labels to the inputs\n",
        "    return inputs\n"
      ],
      "metadata": {
        "id": "i7BLX9IJctSo",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:54:04.160320Z",
          "iopub.execute_input": "2024-10-08T23:54:04.160683Z",
          "iopub.status.idle": "2024-10-08T23:54:06.798180Z",
          "shell.execute_reply.started": "2024-10-08T23:54:04.160644Z",
          "shell.execute_reply": "2024-10-08T23:54:06.797189Z"
        },
        "trusted": true,
        "outputId": "242ace50-ad6a-4fc9-ef37-1df311723550",
        "colab": {
          "referenced_widgets": [
            "32a843e442ff43aea8055cb5056c3e7b",
            "3a37096c971042938efdfe820c16865c",
            "34af90b8ed904ebe8ea2b5146356eff3"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32a843e442ff43aea8055cb5056c3e7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a37096c971042938efdfe820c16865c"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:302: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34af90b8ed904ebe8ea2b5146356eff3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        }
      ],
      "id": "i7BLX9IJctSo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load a Saved Processed Dataset or Start Training One\n",
        "\n",
        "Only start processing the dataset if you think there is going to be improvement to the training process later on. One is provided for you to save time.\n",
        "\n",
        "### Preprocessing a Dataset with a Feature Extractor before Training\n",
        "\n",
        "Preprocessing a dataset with a feature extractor before training is essential for several reasons, especially when working with audio, image, or text data. Here's why:\n",
        "\n",
        "#### 1. Normalization\n",
        "Feature extraction ensures that the input data is normalized to a standard format, which helps the model learn efficiently. For example, in audio processing, feature extractors like Wav2Vec2 convert raw waveforms into a consistent feature representation (e.g., mel spectrograms or embeddings).\n",
        "\n",
        "#### 2. Dimensionality Reduction\n",
        "Extracting key features reduces the dimensionality of the data, removing redundant or irrelevant information. This helps in making the training process more efficient by focusing on the most important patterns in the data.\n",
        "\n",
        "#### 3. Consistency\n",
        "Raw data like audio or text can vary significantly in length or format (e.g., different sampling rates, noise levels, or accents). Feature extraction standardizes the input, ensuring that the model receives consistent input across the dataset.\n",
        "\n",
        "#### 4. Improved Learning\n",
        "Models typically perform better when trained on features that highlight relevant patterns. For instance, in speech emotion recognition, feature extraction might focus on intonation, pitch, and pauses, which are more useful for emotion detection than raw audio.\n",
        "\n",
        "#### 5. Faster Convergence\n",
        "By transforming the raw data into a more compact and informative representation, feature extraction can help the model converge faster during training, reducing the computational cost.\n"
      ],
      "metadata": {
        "id": "WKoGMzHFHcxz"
      },
      "id": "WKoGMzHFHcxz"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Install gdown if not already installed\n",
        "!pip install gdown\n",
        "\n",
        "# Download the file from Google Drive\n",
        "import gdown\n",
        "\n",
        "# Google Drive file URL\n",
        "file_url = \"https://drive.google.com/uc?id=1QvTdLI6TAWIlot9gVw4eGgAQgdaqSQA3\"\n",
        "\n",
        "# Specify the output file name\n",
        "output = \"downloaded_file.zip\"\n",
        "\n",
        "# Download the file\n",
        "gdown.download(file_url, output, quiet=False)\n",
        "\n",
        "# Unzip the downloaded file\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"unzipped_files\")\n",
        "\n",
        "# List the extracted files\n",
        "os.listdir(\"unzipped_files\")\n",
        "\n",
        "# Remove the zip file\n",
        "import os\n",
        "os.remove(output)\n",
        "'''"
      ],
      "metadata": {
        "id": "t7G8HKvuYQL5"
      },
      "id": "t7G8HKvuYQL5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load or process the dataset\n",
        "LOAD = False # Set to true if you already have a processed_dataset one can be found in this link if you want to save time its from Azreen Gdrive https://drive.google.com/file/d/1QvTdLI6TAWIlot9gVw4eGgAQgdaqSQA3/view?usp=drive_link\n",
        "\n",
        "if LOAD:\n",
        "    from datasets import load_from_disk\n",
        "    emotion_dataset = load_from_disk('/kaggle/input/small-project-dataset/dataset/processed_dataset') #Change to Collab/Kaggle Directory\n",
        "    print(\"Processed dataset loaded\")\n",
        "else:\n",
        "    emotion_dataset = emotion_dataset.map(preprocess_function, batched=True)\n",
        "    emotion_dataset.save_to_disk('./processed_dataset') #Change to Collab/Kaggle Directory\n",
        "\n",
        "feature_extractor.save_pretrained(\"./wav2vec2-test\") #Change to Collab/Kaggle Directory\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    accuracy = np.mean(preds == labels)\n",
        "    return {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "WcVe-thucxeN",
        "execution": {
          "iopub.status.busy": "2024-10-08T23:54:06.802449Z",
          "iopub.execute_input": "2024-10-08T23:54:06.802874Z",
          "iopub.status.idle": "2024-10-08T23:54:06.980061Z",
          "shell.execute_reply.started": "2024-10-08T23:54:06.802834Z",
          "shell.execute_reply": "2024-10-08T23:54:06.979100Z"
        },
        "trusted": true,
        "outputId": "c92ec723-dfa4-43c9-db30-c8d12f60dcde"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Processed dataset loaded\n",
          "output_type": "stream"
        }
      ],
      "id": "WcVe-thucxeN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declare Optimizer (Adam)\n"
      ],
      "metadata": {
        "id": "pwPDpkknIHiA"
      },
      "id": "pwPDpkknIHiA"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T01:45:42.141556Z",
          "iopub.execute_input": "2024-10-09T01:45:42.142379Z",
          "iopub.status.idle": "2024-10-09T01:45:42.152226Z",
          "shell.execute_reply.started": "2024-10-09T01:45:42.142314Z",
          "shell.execute_reply": "2024-10-09T01:45:42.151074Z"
        },
        "trusted": true,
        "id": "MSH1MjYHGdWG",
        "outputId": "4ad99f22-2d27-4d37-d820-7eef09546c3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "id": "MSH1MjYHGdWG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "yH4rWLM0IOYt"
      },
      "id": "yH4rWLM0IOYt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=5)\n",
        "\n",
        "print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.to('cuda')\n",
        "    print(\"Model moved to GPU.\")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./wav2vec2-test\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    weight_decay = 0.1,  # Regularization to prevent overfitting\n",
        "    gradient_accumulation_steps = 2,  # Simulates a larger batch size without increasing memory usage\n",
        "    warmup_steps = 100,  # Number of steps for learning rate warmup\n",
        "    learning_rate = 1e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    logging_steps= 1,\n",
        "    num_train_epochs=epochs,\n",
        "    save_steps=10,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    fp16=True,\n",
        "    dataloader_pin_memory=True,\n",
        "    load_best_model_at_end=True,\n",
        "    dataloader_num_workers=0,\n",
        "    report_to=\"none\"  # Add a unique name for this training run\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=emotion_dataset[\"train\"],\n",
        "    eval_dataset=emotion_dataset[\"val\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    optimizers=(optimizer, None),  # Pass the optimizer, scheduler can be None\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "nvugieZhc10h",
        "execution": {
          "iopub.status.busy": "2024-10-09T01:45:44.014476Z",
          "iopub.execute_input": "2024-10-09T01:45:44.014931Z",
          "iopub.status.idle": "2024-10-09T03:54:26.765727Z",
          "shell.execute_reply.started": "2024-10-09T01:45:44.014889Z",
          "shell.execute_reply": "2024-10-09T03:54:26.764692Z"
        },
        "trusted": true,
        "outputId": "384bf67b-ce5d-4fdb-e079-074513b868c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Is CUDA available: True\nModel moved to GPU.\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='764' max='1035' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 764/1035 2:08:29 < 45:41, 0.10 it/s, Epoch 10/15]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>1.028200</td>\n      <td>1.113257</td>\n      <td>0.495512</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.882500</td>\n      <td>0.975748</td>\n      <td>0.596050</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.730500</td>\n      <td>0.983623</td>\n      <td>0.621185</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.575800</td>\n      <td>0.994184</td>\n      <td>0.644524</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.466800</td>\n      <td>0.980187</td>\n      <td>0.658887</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.376300</td>\n      <td>1.074139</td>\n      <td>0.653501</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "execution_count": 50,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=764, training_loss=0.6690670133261156, metrics={'train_runtime': 7722.171, 'train_samples_per_second': 8.636, 'train_steps_per_second': 0.134, 'total_flos': 2.664012126657024e+18, 'train_loss': 0.6690670133261156, 'epoch': 10.992805755395683})"
          },
          "metadata": {}
        }
      ],
      "id": "nvugieZhc10h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Metrics"
      ],
      "metadata": {
        "id": "N--GRF1jIQO8"
      },
      "id": "N--GRF1jIQO8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ],
      "metadata": {
        "id": "g8C4hhiWdEq_",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:08:22.094465Z",
          "iopub.execute_input": "2024-10-09T04:08:22.095602Z",
          "iopub.status.idle": "2024-10-09T04:09:18.748527Z",
          "shell.execute_reply.started": "2024-10-09T04:08:22.095542Z",
          "shell.execute_reply": "2024-10-09T04:09:18.747575Z"
        },
        "trusted": true,
        "outputId": "f2d1d507-6e51-4269-fa47-41fc2fe02d59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [18/18 00:50]\n    </div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.9421173930168152, 'eval_accuracy': 0.6481149012567325, 'eval_runtime': 56.6437, 'eval_samples_per_second': 9.833, 'eval_steps_per_second': 0.318, 'epoch': 10.992805755395683}\n",
          "output_type": "stream"
        }
      ],
      "id": "g8C4hhiWdEq_"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_save_path = \"/kaggle/working/wav2vec2-emotion-model\" # Change filepath\n",
        "model.save_pretrained(model_save_path)\n",
        "\n",
        "# Save the feature extractor\n",
        "feature_extractor.save_pretrained(model_save_path)\n",
        "\n",
        "print(f\"Model and feature extractor saved to {model_save_path}\")"
      ],
      "metadata": {
        "id": "aBsQX1M7roG5",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:09:37.535576Z",
          "iopub.execute_input": "2024-10-09T04:09:37.536091Z",
          "iopub.status.idle": "2024-10-09T04:09:38.255007Z",
          "shell.execute_reply.started": "2024-10-09T04:09:37.536049Z",
          "shell.execute_reply": "2024-10-09T04:09:38.253686Z"
        },
        "trusted": true,
        "outputId": "f3fbba69-50d4-49b6-ae42-0a3730a17934"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model and feature extractor saved to /kaggle/working/wav2vec2-emotion-model\n",
          "output_type": "stream"
        }
      ],
      "id": "aBsQX1M7roG5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visulazation for better analysis\n",
        "\n",
        "## Plot Training and Validation Loss per Epoch"
      ],
      "metadata": {
        "id": "MbvkAEOuIXEX"
      },
      "id": "MbvkAEOuIXEX"
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract log history\n",
        "log_history = trainer.state.log_history\n",
        "\n",
        "# Extract training and validation loss per epoch\n",
        "training_loss = []\n",
        "validation_loss = []\n",
        "epochs_logged = []\n",
        "\n",
        "for log in log_history:\n",
        "    if \"loss\" in log:  # Training loss\n",
        "        training_loss.append(log[\"loss\"])\n",
        "        epochs_logged.append(log[\"epoch\"])\n",
        "    if \"eval_loss\" in log:  # Validation loss\n",
        "        validation_loss.append(log[\"eval_loss\"])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T04:09:40.187134Z",
          "iopub.execute_input": "2024-10-09T04:09:40.187839Z",
          "iopub.status.idle": "2024-10-09T04:09:40.193777Z",
          "shell.execute_reply.started": "2024-10-09T04:09:40.187793Z",
          "shell.execute_reply": "2024-10-09T04:09:40.192813Z"
        },
        "trusted": true,
        "id": "FKzFV75FGdWH"
      },
      "execution_count": null,
      "outputs": [],
      "id": "FKzFV75FGdWH"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation Loss: {len(validation_loss)}\")\n",
        "print(f\"Loss log: {len(training_loss)}\")\n",
        "print(f\"Epochs Logged: {len(epochs_logged)}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T04:09:43.776801Z",
          "iopub.execute_input": "2024-10-09T04:09:43.777250Z",
          "iopub.status.idle": "2024-10-09T04:09:43.783113Z",
          "shell.execute_reply.started": "2024-10-09T04:09:43.777207Z",
          "shell.execute_reply": "2024-10-09T04:09:43.782112Z"
        },
        "trusted": true,
        "id": "tjaWXjpdGdWH",
        "outputId": "5e8f102a-bc49-472f-f9a8-f36b25554d6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Validation Loss: 12\nLoss log: 11\nEpochs Logged: 11\n",
          "output_type": "stream"
        }
      ],
      "id": "tjaWXjpdGdWH"
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Validation Loss: {validation_loss}\")\n",
        "print(f\"Loss log: {training_loss}\")\n",
        "print(f\"Epochs Logged: {epochs_logged}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T04:09:45.934759Z",
          "iopub.execute_input": "2024-10-09T04:09:45.935161Z",
          "iopub.status.idle": "2024-10-09T04:09:45.940618Z",
          "shell.execute_reply.started": "2024-10-09T04:09:45.935122Z",
          "shell.execute_reply": "2024-10-09T04:09:45.939491Z"
        },
        "trusted": true,
        "id": "WUflhHa6GdWH",
        "outputId": "812d0f66-3f9f-44be-9951-09b7a39f4eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Validation Loss: [1.1132571697235107, 1.0548527240753174, 0.9757477045059204, 0.9611093401908875, 0.9836232662200928, 0.9421173930168152, 0.9941842555999756, 1.0552035570144653, 0.9801869988441467, 1.0427708625793457, 1.0741393566131592, 0.9421173930168152]\nLoss log: [1.0282, 0.9626, 0.8825, 0.7939, 0.7305, 0.6373, 0.5758, 0.4996, 0.4668, 0.4068, 0.3763]\nEpochs Logged: [0.9928057553956835, 2.0, 2.9928057553956835, 4.0, 4.9928057553956835, 6.0, 6.9928057553956835, 8.0, 8.992805755395683, 10.0, 10.992805755395683]\n",
          "output_type": "stream"
        }
      ],
      "id": "WUflhHa6GdWH"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure validation loss is padded to match length of training loss (if necessary)\n",
        "if len(validation_loss) < len(training_loss):\n",
        "    validation_loss += [validation_loss[-1]] * (len(training_loss) - len(validation_loss))\n",
        "if len(validation_loss) > len(training_loss):\n",
        "    validation_loss.pop()\n",
        "# Plot training and validation loss\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(epochs_logged, training_loss, label=\"Training Loss\")\n",
        "plt.plot(epochs_logged, validation_loss, label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Validation Loss per Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T04:09:50.489464Z",
          "iopub.execute_input": "2024-10-09T04:09:50.490369Z",
          "iopub.status.idle": "2024-10-09T04:09:50.829189Z",
          "shell.execute_reply.started": "2024-10-09T04:09:50.490324Z",
          "shell.execute_reply": "2024-10-09T04:09:50.828149Z"
        },
        "trusted": true,
        "id": "neZhhKEpGdWH",
        "outputId": "b60606c5-61fa-496a-9b99-f018567b7b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 1000x600 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ],
      "id": "neZhhKEpGdWH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the Model and zipped it for download for future use"
      ],
      "metadata": {
        "id": "YvF8UFvuIj_Z"
      },
      "id": "YvF8UFvuIj_Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# 圧縮するフォルダと出力するZIPファイル名\n",
        "model_save_path = '/kaggle/working/wav2vec2-emotion-model'\n",
        "zip_file_path = '/kaggle/working/wav2vec2-emotion-model.zip'\n",
        "\n",
        "# フォルダをZIPファイルに圧縮\n",
        "shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', model_save_path)\n",
        "\n",
        "# ZIPファイルへのリンクを表示\n",
        "FileLink(zip_file_path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T04:09:55.295959Z",
          "iopub.execute_input": "2024-10-09T04:09:55.296740Z",
          "iopub.status.idle": "2024-10-09T04:10:17.367538Z",
          "shell.execute_reply.started": "2024-10-09T04:09:55.296675Z",
          "shell.execute_reply": "2024-10-09T04:10:17.366495Z"
        },
        "trusted": true,
        "id": "dKDj_ghmGdWH",
        "outputId": "a519034c-25cf-4973-a66f-35f475e9bafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 57,
          "output_type": "execute_result",
          "data": {
            "text/plain": "/kaggle/working/wav2vec2-emotion-model.zip",
            "text/html": "<a href='/kaggle/working/wav2vec2-emotion-model.zip' target='_blank'>/kaggle/working/wav2vec2-emotion-model.zip</a><br>"
          },
          "metadata": {}
        }
      ],
      "id": "dKDj_ghmGdWH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Phase\n",
        "\n",
        "You only need to run this part if you altrady have finished training the model or have one downloaded. The code is setup in a way that  that you can drag and drop your model of choice to predict. So while we settled on wav2vec2 you can change it and we will show where and how you need to tweak it for that to happen."
      ],
      "metadata": {
        "id": "3oin8qAPggTe"
      },
      "id": "3oin8qAPggTe"
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoFeatureExtractor, AutoModelForAudioClassification\n",
        "from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2FeatureExtractor\n",
        "import glob\n",
        "import csv"
      ],
      "metadata": {
        "id": "c49zYa1WuwJU",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:10:23.167854Z",
          "iopub.execute_input": "2024-10-09T04:10:23.168261Z",
          "iopub.status.idle": "2024-10-09T04:10:23.173469Z",
          "shell.execute_reply.started": "2024-10-09T04:10:23.168220Z",
          "shell.execute_reply": "2024-10-09T04:10:23.172287Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "c49zYa1WuwJU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the path to your test folder\n",
        "target_sampling_rate = 16000\n",
        "test_folder_path = r'/kaggle/input/small-project-dataset/dataset/test' #Change to Collab/Kaggle Directory"
      ],
      "metadata": {
        "id": "CzP5YcTauyQU",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:10:25.303603Z",
          "iopub.execute_input": "2024-10-09T04:10:25.304008Z",
          "iopub.status.idle": "2024-10-09T04:10:25.308920Z",
          "shell.execute_reply.started": "2024-10-09T04:10:25.303968Z",
          "shell.execute_reply": "2024-10-09T04:10:25.307678Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "CzP5YcTauyQU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Feature Extractor\n",
        "## Aditionally take note of the Labels for remapping\n"
      ],
      "metadata": {
        "id": "E_-JGcdwIvAC"
      },
      "id": "E_-JGcdwIvAC"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved model\n",
        "# Path where the model and feature extractor are saved\n",
        "model_save_path = \"/kaggle/working/wav2vec2-emotion-model\" #Change to Collab/Kaggle Directory\n",
        "\n",
        "# Load the model\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(model_save_path)\n",
        "\n",
        "# Load the feature extractor\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained('facebook/wav2vec2-base-960h')\n",
        "\n",
        "print(\"Model and feature extractor loaded successfully!\")\n",
        "print(f\"Model Labels:  {model.config.id2label}\")\n",
        "print(\"Wanted Labels: {0: 'ang', 1: 'hap', 2: 'neu', 3: 'sad'}\")"
      ],
      "metadata": {
        "id": "JTdFs-tyu0Gc",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:10:27.281713Z",
          "iopub.execute_input": "2024-10-09T04:10:27.282131Z",
          "iopub.status.idle": "2024-10-09T04:10:27.516531Z",
          "shell.execute_reply.started": "2024-10-09T04:10:27.282092Z",
          "shell.execute_reply": "2024-10-09T04:10:27.515404Z"
        },
        "trusted": true,
        "outputId": "6e6df5be-28fc-4d90-c866-4838bce61ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model and feature extractor loaded successfully!\nModel Labels:  {0: 'LABEL_0', 1: 'LABEL_1', 2: 'LABEL_2', 3: 'LABEL_3'}\nWanted Labels: {0: 'ang', 1: 'hap', 2: 'neu', 3: 'sad'}\n",
          "output_type": "stream"
        }
      ],
      "id": "JTdFs-tyu0Gc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Prediction Function"
      ],
      "metadata": {
        "id": "-cNGwms9I-ON"
      },
      "id": "-cNGwms9I-ON"
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(test_folder_path, output_csv='prediction.csv'):\n",
        "\n",
        "    # Get a list of all .wav files in the test folder\n",
        "    audio_files = glob.glob(os.path.join(test_folder_path, '*.wav'))\n",
        "\n",
        "    # Prepare a list to hold the results\n",
        "    results = []\n",
        "    count = 1\n",
        "\n",
        "\n",
        "    # Iterate over each audio file in the test folder\n",
        "    for audio_file in audio_files:\n",
        "\n",
        "        print(f'File: {count}', end='\\r')\n",
        "        count += 1\n",
        "\n",
        "        # Load the audio file\n",
        "        y_ini, sr_ini = librosa.load(audio_file, sr=target_sampling_rate)\n",
        "\n",
        "        # Extract features from the audio\n",
        "        inputs = feature_extractor(y_ini, sampling_rate=target_sampling_rate, return_tensors=\"pt\")\n",
        "\n",
        "        # Get the logits from the model\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs).logits\n",
        "\n",
        "        # Predict the class with the highest logit value\n",
        "        predicted_class_id = torch.argmax(logits).item()\n",
        "\n",
        "        # Extract the filename without the extension\n",
        "        filename = os.path.splitext(os.path.basename(audio_file))[0]\n",
        "\n",
        "        # Append the result to the list\n",
        "        results.append([filename, predicted_class_id])\n",
        "\n",
        "    # Write the results to a CSV file\n",
        "    with open(output_csv, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        # Write header\n",
        "        writer.writerow(['ID', 'Predict'])\n",
        "        # Write data\n",
        "        writer.writerows(results)\n",
        "\n",
        "    print(f\"Predictions saved to {output_csv}\")"
      ],
      "metadata": {
        "id": "AtxMTb8G0VBT",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:10:30.443551Z",
          "iopub.execute_input": "2024-10-09T04:10:30.444280Z",
          "iopub.status.idle": "2024-10-09T04:10:30.454619Z",
          "shell.execute_reply.started": "2024-10-09T04:10:30.444237Z",
          "shell.execute_reply": "2024-10-09T04:10:30.453471Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "AtxMTb8G0VBT"
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-09T04:10:36.197390Z",
          "iopub.execute_input": "2024-10-09T04:10:36.198289Z",
          "iopub.status.idle": "2024-10-09T04:10:36.202404Z",
          "shell.execute_reply.started": "2024-10-09T04:10:36.198246Z",
          "shell.execute_reply": "2024-10-09T04:10:36.201235Z"
        },
        "trusted": true,
        "id": "wCT2ZAPmGdWI"
      },
      "execution_count": null,
      "outputs": [],
      "id": "wCT2ZAPmGdWI"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the prediction"
      ],
      "metadata": {
        "id": "G62dU33IJImo"
      },
      "id": "G62dU33IJImo"
    },
    {
      "cell_type": "code",
      "source": [
        "predict(test_folder_path)"
      ],
      "metadata": {
        "id": "UAmBSMvO0WbT",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:10:44.125020Z",
          "iopub.execute_input": "2024-10-09T04:10:44.125797Z",
          "iopub.status.idle": "2024-10-09T04:14:36.135703Z",
          "shell.execute_reply.started": "2024-10-09T04:10:44.125720Z",
          "shell.execute_reply": "2024-10-09T04:14:36.134666Z"
        },
        "trusted": true,
        "outputId": "8f87472b-722c-40f9-ef81-588b57bdc128"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Predictions saved to prediction.csv\n",
          "output_type": "stream"
        }
      ],
      "id": "UAmBSMvO0WbT"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import confusion_matrix, classification_report, recall_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "UZfYSJeC0aOW",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:14:38.724697Z",
          "iopub.execute_input": "2024-10-09T04:14:38.725689Z",
          "iopub.status.idle": "2024-10-09T04:14:38.731066Z",
          "shell.execute_reply.started": "2024-10-09T04:14:38.725641Z",
          "shell.execute_reply": "2024-10-09T04:14:38.729815Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "UZfYSJeC0aOW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Declare the confusion matrix"
      ],
      "metadata": {
        "id": "Dg3_UnsVJPOL"
      },
      "id": "Dg3_UnsVJPOL"
    },
    {
      "cell_type": "code",
      "source": [
        "def show_confusion_matrix(file1, file2, save):\n",
        "\n",
        "    # Read the TSV files\n",
        "    df1 = pd.read_csv(file1, sep='\\t')\n",
        "    df2 = pd.read_csv(file2)\n",
        "\n",
        "    # Remap predictions before reading as every model have their own label name but since we trained it before hand to handle the label this is for analysis purpose\n",
        "    '''\n",
        "    (N)eutral Mapped to: 2\n",
        "    (H)appy Mapped to: 1\n",
        "    (S)ad Mapped to: 3\n",
        "    (A)ngry Mapped to: 0\n",
        "    '''\n",
        "\n",
        "    # Define a remapping dictionary\n",
        "    remap_dict = {\n",
        "        0: 'A',\n",
        "        1: 'H',\n",
        "        2: 'N',\n",
        "        3: 'S'\n",
        "    }\n",
        "\n",
        "    # Apply the remap function to the 'Predict' column\n",
        "    df2['Predict'] = df2['Predict'].map(remap_dict)\n",
        "\n",
        "    # Merge DataFrames on 'filename'\n",
        "    df_merged = pd.merge(df1[['filename', 'label']],df2[['ID', 'Predict']],left_on='filename',right_on='ID')\n",
        "\n",
        "    # Extract true labels and predictions\n",
        "    y_true = df_merged['label']\n",
        "    y_pred = df_merged['Predict']\n",
        "\n",
        "    # Compute the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Create a DataFrame for the confusion matrix\n",
        "    labels = sorted(y_true.unique())\n",
        "    cm_df = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.ylabel('Actual Labels')\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "    # Compute and print accuracy\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "    # Compute and print UA score\n",
        "    macro_recall = recall_score(y_true, y_pred, average='macro')\n",
        "    print(f\"test UA: {macro_recall}\")\n",
        "\n",
        "    # Print the confusion matrix\n",
        "    #print(\"Confusion Matrix:\")\n",
        "    #print(cm_df)\n",
        "\n",
        "    # Compute and print classification report\n",
        "    report = classification_report(y_true, y_pred, labels=labels)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "\n",
        "    if save:\n",
        "        # Save the updated dataframe back to a CSV file\n",
        "        df_merged.to_csv('prediction_results.csv', index=False)\n",
        "        print(\"Saved\")\n"
      ],
      "metadata": {
        "id": "bqzNl4cV0bQr",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:14:41.085569Z",
          "iopub.execute_input": "2024-10-09T04:14:41.085975Z",
          "iopub.status.idle": "2024-10-09T04:14:41.097718Z",
          "shell.execute_reply.started": "2024-10-09T04:14:41.085936Z",
          "shell.execute_reply": "2024-10-09T04:14:41.096652Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "bqzNl4cV0bQr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the tsv and the prediction.csv"
      ],
      "metadata": {
        "id": "lB0Hm7RiJSTo"
      },
      "id": "lB0Hm7RiJSTo"
    },
    {
      "cell_type": "code",
      "source": [
        "tsv_file = r'/kaggle/input/small-project-dataset/dataset/IEMOCAP_4.tsv'  #Change to Collab/Kaggle Directory\n",
        "\n",
        "# For Validation of code\n",
        "predictions = [\n",
        "   '/kaggle/working/prediction.csv', #Change to Collab/Kaggle Directory\n",
        "]\n"
      ],
      "metadata": {
        "id": "4ZAtsBhM0cSa",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:14:43.481874Z",
          "iopub.execute_input": "2024-10-09T04:14:43.482283Z",
          "iopub.status.idle": "2024-10-09T04:14:43.486968Z",
          "shell.execute_reply.started": "2024-10-09T04:14:43.482243Z",
          "shell.execute_reply": "2024-10-09T04:14:43.485879Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [],
      "id": "4ZAtsBhM0cSa"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display the confusion matrix for additional insight"
      ],
      "metadata": {
        "id": "O-TcbAPHJWQh"
      },
      "id": "O-TcbAPHJWQh"
    },
    {
      "cell_type": "code",
      "source": [
        "for prediction in reversed(predictions):\n",
        "    print(f\"FILEPATH: {prediction}\")\n",
        "    show_confusion_matrix(tsv_file, prediction, False)"
      ],
      "metadata": {
        "id": "bkkSsZic0dX6",
        "execution": {
          "iopub.status.busy": "2024-10-09T04:14:45.375220Z",
          "iopub.execute_input": "2024-10-09T04:14:45.376239Z",
          "iopub.status.idle": "2024-10-09T04:14:45.780751Z",
          "shell.execute_reply.started": "2024-10-09T04:14:45.376196Z",
          "shell.execute_reply": "2024-10-09T04:14:45.779613Z"
        },
        "trusted": true,
        "outputId": "3bdee934-14d9-4bfb-e439-44c6c67dcb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "FILEPATH: /kaggle/working/prediction.csv\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 800x600 with 2 Axes>",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIjCAYAAABvUIGpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABRrklEQVR4nO3dd3gU5f7+8XuTkE1ISEKAkATpHemo9GoQERAERRSVKoogUmx4BASFAEoRpBykoyIW5AAWRBAQQQWkSi/SQ09CAikk8/uDH/t1GZAEdjMJ+36da67LfWZ29rObA3xyPzPP2gzDMAQAAAD8g5fVBQAAACD7oUkEAACACU0iAAAATGgSAQAAYEKTCAAAABOaRAAAAJjQJAIAAMCEJhEAAAAmNIkAAAAwoUkE8K/27dunhx56SMHBwbLZbFq0aJFLz//333/LZrNp9uzZLj1vTtaoUSM1atTI6jIAeDiaRCAHOHDggF544QWVKFFCfn5+CgoKUt26dfXhhx/q8uXLbn3tTp06afv27Ro+fLjmzZun++67z62vl5U6d+4sm82moKCgG36O+/btk81mk81m0wcffJDp8584cULvvPOOtmzZ4oJqASBr+VhdAIB/9+233+qJJ56Q3W7Xc889p4oVKyolJUVr167Va6+9pr/++kvTpk1zy2tfvnxZ69ev13/+8x/17t3bLa9RtGhRXb58Wbly5XLL+W/Fx8dHly5d0pIlS9S+fXunfZ9++qn8/PyUlJR0W+c+ceKEhg4dqmLFiqlq1aoZft6PP/54W68HAK5EkwhkY4cOHVKHDh1UtGhRrVy5UhEREY59vXr10v79+/Xtt9+67fXPnDkjSQoJCXHba9hsNvn5+bnt/Ldit9tVt25dzZ8/39QkfvbZZ2rRooW+/vrrLKnl0qVLyp07t3x9fbPk9QDg3zDdDGRjo0ePVkJCgmbMmOHUIF5TqlQpvfLKK47HV65c0bvvvquSJUvKbrerWLFieuutt5ScnOz0vGLFiqlly5Zau3atHnjgAfn5+alEiRKaO3eu45h33nlHRYsWlSS99tprstlsKlasmKSr07TX/vuf3nnnHdlsNqex5cuXq169egoJCVFgYKDKli2rt956y7H/Ztckrly5UvXr11dAQIBCQkLUunVr7dq164avt3//fnXu3FkhISEKDg5Wly5ddOnSpZt/sNd5+umn9f333ys2NtYxtmHDBu3bt09PP/206fjz58/r1VdfVaVKlRQYGKigoCA1b95cW7dudRyzatUq3X///ZKkLl26OKatr73PRo0aqWLFitq0aZMaNGig3LlzOz6X669J7NSpk/z8/Ezvv1mzZsqbN69OnDiR4fcKABlFkwhkY0uWLFGJEiVUp06dDB3fvXt3DR48WNWrV9e4cePUsGFDRUdHq0OHDqZj9+/fr8cff1xNmzbVmDFjlDdvXnXu3Fl//fWXJKlt27YaN26cJOmpp57SvHnzNH78+EzV/9dff6lly5ZKTk7WsGHDNGbMGD366KP69ddf//V5P/30k5o1a6bTp0/rnXfeUf/+/bVu3TrVrVtXf//9t+n49u3b6+LFi4qOjlb79u01e/ZsDR06NMN1tm3bVjabTQsXLnSMffbZZypXrpyqV69uOv7gwYNatGiRWrZsqbFjx+q1117T9u3b1bBhQ0fDVr58eQ0bNkyS1KNHD82bN0/z5s1TgwYNHOc5d+6cmjdvrqpVq2r8+PFq3LjxDev78MMPVaBAAXXq1ElpaWmSpP/+97/68ccfNXHiREVGRmb4vQJAhhkAsqW4uDhDktG6desMHb9lyxZDktG9e3en8VdffdWQZKxcudIxVrRoUUOSsWbNGsfY6dOnDbvdbgwYMMAxdujQIUOS8f777zuds1OnTkbRokVNNQwZMsT4518r48aNMyQZZ86cuWnd115j1qxZjrGqVasaYWFhxrlz5xxjW7duNby8vIznnnvO9Hpdu3Z1Oudjjz1m5MuX76av+c/3ERAQYBiGYTz++OPGgw8+aBiGYaSlpRnh4eHG0KFDb/gZJCUlGWlpaab3YbfbjWHDhjnGNmzYYHpv1zRs2NCQZEydOvWG+xo2bOg0tmzZMkOS8d577xkHDx40AgMDjTZt2tzyPQLA7SJJBLKp+Ph4SVKePHkydPx3330nSerfv7/T+IABAyTJdO1ihQoVVL9+fcfjAgUKqGzZsjp48OBt13y9a9cy/u9//1N6enqGnnPy5Elt2bJFnTt3VmhoqGO8cuXKatq0qeN9/tOLL77o9Lh+/fo6d+6c4zPMiKefflqrVq1STEyMVq5cqZiYmBtONUtXr2P08rr612daWprOnTvnmEr/888/M/yadrtdXbp0ydCxDz30kF544QUNGzZMbdu2lZ+fn/773/9m+LUAILNoEoFsKigoSJJ08eLFDB1/+PBheXl5qVSpUk7j4eHhCgkJ0eHDh53GixQpYjpH3rx5deHChdus2OzJJ59U3bp11b17dxUsWFAdOnTQF1988a8N47U6y5Yta9pXvnx5nT17VomJiU7j17+XvHnzSlKm3ssjjzyiPHnyaMGCBfr00091//33mz7La9LT0zVu3DiVLl1adrtd+fPnV4ECBbRt2zbFxcVl+DULFSqUqZtUPvjgA4WGhmrLli2aMGGCwsLCMvxcAMgsmkQgmwoKClJkZKR27NiRqeddf+PIzXh7e99w3DCM236Na9fLXePv7681a9bop59+0rPPPqtt27bpySefVNOmTU3H3ok7eS/X2O12tW3bVnPmzNE333xz0xRRkkaMGKH+/furQYMG+uSTT7Rs2TItX75c9957b4YTU+nq55MZmzdv1unTpyVJ27dvz9RzASCzaBKBbKxly5Y6cOCA1q9ff8tjixYtqvT0dO3bt89p/NSpU4qNjXXcqewKefPmdboT+Jrr00pJ8vLy0oMPPqixY8dq586dGj58uFauXKmff/75hue+VueePXtM+3bv3q38+fMrICDgzt7ATTz99NPavHmzLl68eMObfa756quv1LhxY82YMUMdOnTQQw89pKioKNNnktGGPSMSExPVpUsXVahQQT169NDo0aO1YcMGl50fAK5HkwhkY6+//roCAgLUvXt3nTp1yrT/wIED+vDDDyVdnS6VZLoDeezYsZKkFi1auKyukiVLKi4uTtu2bXOMnTx5Ut98843TcefPnzc999qi0tcvy3NNRESEqlatqjlz5jg1XTt27NCPP/7oeJ/u0LhxY7377rv66KOPFB4eftPjvL29TSnll19+qePHjzuNXWtmb9RQZ9Ybb7yhI0eOaM6cORo7dqyKFSumTp063fRzBIA7xWLaQDZWsmRJffbZZ3ryySdVvnx5p29cWbdunb788kt17txZklSlShV16tRJ06ZNU2xsrBo2bKg//vhDc+bMUZs2bW66vMrt6NChg9544w099thj6tOnjy5duqQpU6aoTJkyTjduDBs2TGvWrFGLFi1UtGhRnT59WpMnT9Y999yjevXq3fT877//vpo3b67atWurW7duunz5siZOnKjg4GC98847Lnsf1/Py8tLbb799y+NatmypYcOGqUuXLqpTp462b9+uTz/9VCVKlHA6rmTJkgoJCdHUqVOVJ08eBQQEqGbNmipevHim6lq5cqUmT56sIUOGOJbkmTVrlho1aqRBgwZp9OjRmTofAGSIxXdXA8iAvXv3Gs8//7xRrFgxw9fX18iTJ49Rt25dY+LEiUZSUpLjuNTUVGPo0KFG8eLFjVy5chmFCxc2Bg4c6HSMYVxdAqdFixam17l+6ZWbLYFjGIbx448/GhUrVjR8fX2NsmXLGp988olpCZwVK1YYrVu3NiIjIw1fX18jMjLSeOqpp4y9e/eaXuP6ZWJ++ukno27duoa/v78RFBRktGrVyti5c6fTMdde7/oldmbNmmVIMg4dOnTTz9QwnJfAuZmbLYEzYMAAIyIiwvD39zfq1q1rrF+//oZL1/zvf/8zKlSoYPj4+Di9z4YNGxr33nvvDV/zn+eJj483ihYtalSvXt1ITU11Oq5fv36Gl5eXsX79+n99DwBwO2yGkYkruwEAAOARuCYRAAAAJjSJAAAAMKFJBAAAgAlNIgAAAExoEgEAAGBCkwgAAAATmkQAAACY3JXfuOIfNdLqEpCFDn7d3+oSkIUOn7lkdQnIQlWLhVhdArKQn4VdiX+13m479+XNH7nt3O5EkggAAACTuzJJBAAAyBQbudn1aBIBAABsNqsryHZomwEAAGBCkggAAMB0swmfCAAAAExIEgEAALgm0YQkEQAAACYkiQAAAFyTaMInAgAAABOSRAAAAK5JNKFJBAAAYLrZhE8EAAAAJiSJAAAATDebkCQCAADAhCQRAACAaxJN+EQAAABgQpIIAADANYkmJIkAAAAwIUkEAADgmkQTmkQAAACmm01omwEAAGBCkggAAMB0swmfCAAAAExIEgEAAEgSTfhEAAAAYEKSCAAA4MXdzdcjSQQAAIAJSSIAAADXJJrQJAIAALCYtgltMwAAAExIEgEAAJhuNuETAQAAgAlJIgAAANckmpAkAgAAwIQkEQAAgGsSTfhEAAAAYEKSCAAAwDWJJjSJAAAATDeb8IkAAADAhCQRAACA6WYTkkQAAACYkCQCAABwTaIJnwgAAABMSBIBAAC4JtGEJBEAAAAmJIkAAABck2hCkwgAAECTaMInAgAAABOSRAAAAG5cMSFJBAAAgAlJYjZXt1Jh9WtfU9VLF1RE/jxqP/hrLVm3z+mYQZ3qq8sjVRQSaNf6v46rz4fLdOD4BadjHq5ZUm89U1cVSxRQUkqa1m47ovZDFmblW8Ft2PrnRn3+yWzt3b1T586e0bujx6t+owcd+9f8/JMWL/xCe3ftVHx8nD7+5EuVLlPOwopxu5Z8MVub1q3SyWOHlcvXrtLlK6l9l96KuKeo45hTJ4/p8xkTtO+vrUpNTVGlGrX17IsDFJw3n4WVw1U2bdyg2TNnaNfOHTpz5ozGTZikJg9GWV2W5+CaRBM+kWwuwC+Xth88pb4Tl99w/4Ana+qlx2qoz4fL1KD3XCUmpWrJyCdlz+XtOKZN/bKa8UZLzV22TQ/0mKkmr8zTgpU7s+ot4A4kJV1WydJl1Pe1/9x4/+XLqlSlmnr07pfFlcHV9mzfrAdbPK5BY2bo9fcmKO3KFb3/dh8lJ12WJCUnXdb7b/eRTTa9ET1Jb3/wsdKupGrcsFeVnp5ucfVwhcuXL6ls2bIa+PYQq0uBxdasWaNWrVopMjJSNptNixYtctpvGIYGDx6siIgI+fv7KyoqSvv2OQdI58+fV8eOHRUUFKSQkBB169ZNCQkJmaojWyeJO3bsUMWKFa0uw1I/bjioHzccvOn+Xm3v16hP12np/08Xu49aqsNfvqxH65bRl6t2ydvLpg9eelBvTftZc37Y5nje7iPn3F477lzNOvVVs079m+5/6JFWkqSTJ45nVUlwk1ff/dDpcff+g/Xy0w/r0P7dKlexmvbu3Kqzp0/q3Ylz5Z87UJL0fP8heunJKO3aulH3VnvAirLhQvXqN1S9+g2tLsNzZaNrEhMTE1WlShV17dpVbdu2Ne0fPXq0JkyYoDlz5qh48eIaNGiQmjVrpp07d8rPz0+S1LFjR508eVLLly9XamqqunTpoh49euizzz7LcB3ZLkm8ePGipk2bpgceeEBVqlSxupxsrVhEsCLyBWrln387xuITk7Vh1wnVrFBIklStdLgKFQhSumFo/dQuOrigtxaNeEIViuW3qGoAGXE58epv/IGBQZKkK6mpsskmn1y+jmNy+frKZvPS3p1bLakRgHs0b95c7733nh577DHTPsMwNH78eL399ttq3bq1KleurLlz5+rEiROOxHHXrl364YcfNH36dNWsWVP16tXTxIkT9fnnn+vEiRMZriPbNIlr1qxRp06dFBERoQ8++EBNmjTRb7/9dsvnJScnKz4+3mkz0q9kQcXWC897NU04fSHRafx0bKIKhgZIkopHhEiS3n6unkZ9uk7t3v5SsQlJWjbmaeXN45el9QLImPT0dH06bZxKV6ise4qVlCSVLFdRdj8/fTHrIyUnJSk56bI+nz5B6elpij1/1uKKgbuAzctt2416leTk5Nsq89ChQ4qJiVFU1P9drxocHKyaNWtq/fr1kqT169crJCRE9913n+OYqKgoeXl56ffff8/wa1naJMbExGjkyJEqXbq0nnjiCQUFBSk5OVmLFi3SyJEjdf/999/yHNHR0QoODnbarvy9yv3F5xBeXlfj81GfrdOiX/Zo875T6vH+dzIMqW0DbnAAsqO5U97X8cMH9dIb7znGgoLzqtfAEdr8+1q98HgjvfjEg7qUeFFFS5aVzSvb/L4P5Fw2m9u2G/Uq0dHRt1VmTEyMJKlgwYJO4wULFnTsi4mJUVhYmNN+Hx8fhYaGOo7JCMuuSWzVqpXWrFmjFi1aaPz48Xr44Yfl7e2tqVOnZuo8AwcOVP/+/Z3GwtpMcGWp2VbMhavTUWF5AxRz/v/SxLCQAG07cFqSdPLc1WN2H/6/axBTUtP098lYFQ4LysJqAWTE3Cnva+sfa/XWqP8qNL/zPwKVqtfSBzMW6mJcrLy8vRUQmEd9OjZXWHikRdUCyIgb9Sp2u92iajLOsibx+++/V58+fdSzZ0+VLl36ts9jt9tNH7TNK1vfj+Myf5+M08lzCWpcrZijKcyT21f3l4/Ux0s2S5I274tRUsoVlb4nVOt2HJMk+Xh7qUh4sI6cjrOsdgDODMPQvKkfaNP61RoYPVkF/qXxyxMcIknauXWj4uMuqFrNBllUJXD3srnxxpUb9Sq3Kzw8XJJ06tQpRUREOMZPnTqlqlWrOo45ffq00/OuXLmi8+fPO56fEZZ1U2vXrtWMGTNUo0YNlS9fXs8++6w6dOhgVTnZVoBfLpUslNfxuFhEiCqXDNOFi0k6ejpekxZu0Bsd62j/8fP6OyZOQzrX18lzCVr8615J0sVLKZq+ZLMGdaqnY2fideRUvPq1rylJWrh6tyXvCRl36dIlHT92xPE45sRx7du7W0FBwSoYHqH4uDidOnVS585c/cvg6OG/JUmhofmVLz83J+Ukcye/r99WL9Mrg96Xn3+AYs9fTf9zBwTI1371+uE1y5cosnAx5QnOq/27tuvTaWPVrM1TTmspIue6lJioI0f+78/78WPHtHvXLgUHBysikrQYVxUvXlzh4eFasWKFoymMj4/X77//rp49e0qSateurdjYWG3atEk1atSQJK1cuVLp6emqWbNmhl/LZhiG4fJ3kAmJiYlasGCBZs6cqT/++ENpaWkaO3asunbtqjx58tzWOf2jRrq4SuvUr1JEP4552jQ+b9l29Xj/W0lXF9Pu2qKKQgL9tG7HMb3y4TLt/8di2j7eXnq3W0M91bSi/H19tGH3Cb02eYV2Hb47LnY/+HX/Wx+UQ23etEH9enY1jTdr8agGDhmu75cu0qhhg0z7O3XvqS49XsqKErPc4TOXrC7BLTq1uPFf3N37DlL9pi0lSV/MmqS1Py1VQkK88odFqMkjbdWszVNuTUCsVrVYiNUlZJkNf/yu7l2eM40/2voxvTvi7vl37d/4WTgRGPD4LLedO/GrLpk6PiEhQfv375ckVatWTWPHjlXjxo0VGhqqIkWKaNSoURo5cqTTEjjbtm1zWgKnefPmOnXqlKZOnepYAue+++7L1BI4ljeJ/7Rnzx7NmDFD8+bNU2xsrJo2barFixdn+jx3U5OIW7ubm0SY3a1NIm7Mk5pE0CRes2rVKjVu3Ng03qlTJ82ePVuGYWjIkCGaNm2aYmNjVa9ePU2ePFllypRxHHv+/Hn17t1bS5YskZeXl9q1a6cJEyYoMDAww3VkqybxmrS0NC1ZskQzZ86kScQt0SR6FppEz0KT6FksbRKfcGOT+GXmmsTsIluum+Dt7a02bdrcVoMIAACAO+cZtwEDAAD8i7v52t7bRZMIAAA8Hk2iWbacbgYAAIC1SBIBAIDHI0k0I0kEAACACUkiAADweCSJZiSJAAAAMCFJBAAAIEg0IUkEAACACUkiAADweFyTaEaSCAAAABOSRAAA4PFIEs1oEgEAgMejSTRjuhkAAAAmJIkAAMDjkSSakSQCAADAhCQRAACAINGEJBEAAAAmJIkAAMDjcU2iGUkiAAAATEgSAQCAxyNJNKNJBAAAHo8m0YzpZgAAAJiQJAIAABAkmpAkAgAAwIQkEQAAeDyuSTQjSQQAAIAJSSIAAPB4JIlmJIkAAAAwIUkEAAAejyTRjCYRAAB4PJpEM6abAQAAYEKSCAAAQJBoQpIIAAAAE5JEAADg8bgm0YwkEQAAACYkiQAAwOORJJqRJAIAAMCEJBEAAHg8kkQzmkQAAAB6RBOmmwEAAGBCkggAADwe081mJIkAAAAwIUkEAAAejyTRjCQRAAAAJiSJAADA45EkmpEkAgAAwIQkEQAAeDySRDOaRAAAAHpEE6abAQAAYHJXJolnv3vD6hKQhR4YutzqEpCFBj9+r9UlIAuVSc5jdQnIQn4+3pa9NtPNZiSJAAAAMLkrk0QAAIDMIEk0I0kEAACACUkiAADweASJZiSJAAAAMCFJBAAAHo9rEs1oEgEAgMejRzRjuhkAAAAmJIkAAMDjMd1sRpIIAAAAE5JEAADg8QgSzUgSAQAAYEKSCAAAPJ6XF1Hi9UgSAQAAYEKSCAAAPB7XJJrRJAIAAI/HEjhmTDcDAADAhCQRAAB4PIJEM5JEAAAAmNAkAgAAj2ez2dy2ZUZaWpoGDRqk4sWLy9/fXyVLltS7774rwzAcxxiGocGDBysiIkL+/v6KiorSvn37XP2R0CQCAABkF6NGjdKUKVP00UcfadeuXRo1apRGjx6tiRMnOo4ZPXq0JkyYoKlTp+r3339XQECAmjVrpqSkJJfWwjWJAADA42WXu5vXrVun1q1bq0WLFpKkYsWKaf78+frjjz8kXU0Rx48fr7ffflutW7eWJM2dO1cFCxbUokWL1KFDB5fVQpIIAADgRsnJyYqPj3fakpOTb3hsnTp1tGLFCu3du1eStHXrVq1du1bNmzeXJB06dEgxMTGKiopyPCc4OFg1a9bU+vXrXVo3TSIAAPB4Npv7tujoaAUHBztt0dHRN6zjzTffVIcOHVSuXDnlypVL1apVU9++fdWxY0dJUkxMjCSpYMGCTs8rWLCgY5+rMN0MAAA8njunmwe+OVD9+/d3GrPb7Tc89osvvtCnn36qzz77TPfee6+2bNmivn37KjIyUp06dXJbjTdCkwgAAOBGdrv9pk3h9V577TVHmihJlSpV0uHDhxUdHa1OnTopPDxcknTq1ClFREQ4nnfq1ClVrVrVpXUz3QwAADyeO6ebM+PSpUvy8nJuz7y9vZWeni5JKl68uMLDw7VixQrH/vj4eP3++++qXbv2HX8O/0SSCAAAkE20atVKw4cPV5EiRXTvvfdq8+bNGjt2rLp27Srp6rR437599d5776l06dIqXry4Bg0apMjISLVp08altdAkAgAAj5ddlsCZOHGiBg0apJdeekmnT59WZGSkXnjhBQ0ePNhxzOuvv67ExET16NFDsbGxqlevnn744Qf5+fm5tBab8c8lvO8SiSl33VvCv3hg6HKrS0AWGvz4vVaXgCzUtEy41SUgC4UGeFv22jXe/dlt5940qLHbzu1OJIkAAMDjZZMgMVvhxhUAAACYkCQCAACPl12uScxOSBIBAABgQpIIAAA8HkGiGU0iAADweEw3mzHdDAAAABOSRAAA4PEIEs1IEgEAAGBCkggAADwe1ySakSQCAADAhCQRAAB4PIJEM5JEAAAAmJAkAgAAj8c1iWY0iQAAwOPRI5ox3QwAAAATkkQAAODxmG42I0kEAACACUkiAADweCSJZiSJAAAAMCFJBAAAHo8g0YwkEQAAACYkiTnclwvm68sF83XyxHFJUomSpdTjxV6qW7+BxZXhTnnZpF4PllTLKpHKn8dXp+OT9b/NJzT154OSJB8vm/o0LaX6ZfLrntDcSkhK1foD5zVu2T6duZhscfW4U2v+95l+mj9dtZq31SOdekuSUlNStOyTKdq+7melpaaoVJX71bLrKwoMCbW4WrjCYy2iFHPyhGm87RNP6bWBgyyoyLNwTaIZTWIOF1awoPr0HaAiRYvKMAwtWbxI/fr00vwvF6pkqdJWl4c70K1BcT35QGG99fUO7T+VoIqFgvVeu3t1MemKPl1/RH65vFU+MkhTfz6oPTEXFeSfSwNblNNHz1bVk5N/t7p83IHjB3Zr409LVbBICafxH+ZO0t7Nv+vJvoPllztQS2dN0PyxQ/T8sIkWVQpXmvnJF0pPS3M8PnBgn17p2V0PNm1mYVWegx7RjOnmHK5hoyaq16ChihQtpqLFiqt3n37KnTu3tm/banVpuENVi4Ro5a7TWrPnrE7EJunHv05p3b5zqnRPkCQpIfmKnp+1Sct2nNLfZy9p29E4DV+ySxULBSsi2M/i6nG7kpMu66uJI9S6xwD5B+RxjCddStCfP3+vh5/tqRIVqyuyRBk99uLrOrr3Lx3dt9PCiuEqefOGKl/+Ao7t1zWrVeiewqpW436rS4OHsrRJjI+Pz9CGjElLS9Oy77/V5cuXVLlKVavLwR3aciRWtUrmU9F8uSVJZcMDVa1YiH7Ze/amzwn081F6uqH4pNSsKhMu9u3MD1WmWk2VrFTDafzEwb1KS7uiEv8YL1CoiILzh+no3r+yuky4WWpqipZ9v0QtW7dlGjSL2Gw2t205laXTzSEhIf/64RmGIZvNprR/xO/XS05OVnKy8/VXV2y+stvtLqszu9u3d486P/OUUlKS5Z87t8aM/0glSpayuizcoelrDinQ7qOlfesqzTDkbbPpw+X79e3WmBse7+vjpf7Nyui7bTFKTL75nxlkX9vXrdSJQ/v0wvAppn0JsRfk7ZNL/gGBTuOBwXmVEHshq0pEFln98wolXLyoFo8+ZnUp8GCWNok///yz478Nw9Ajjzyi6dOnq1ChQhk+R3R0tIYOHeo0NvDtwfrPoHdcVWa2V6x4cc3/6hslXLyoFcuXafDbb2r6rHk0ijncwxXD1aJKhF7/Yrv2n05QuYg8erNFWZ25ePUGln/y8bJpbIfKstmkYYuZesyJ4s6e1ndzJqnTW6OVy9fX6nJgsaWLFqpWnfoqUCDM6lI8Rg4O/NzG0iaxYcOGTo+9vb1Vq1YtlShR4ibPMBs4cKD69+/vNHbF5ll/webK5asiRYpKkircW1F/7dihzz6Zq7eHDLO4MtyJAQ+X0Yw1h/T99qvJ4b5TCYoM8VP3hsWdmkQfL5vGPFVZkSH+6jJjIyliDnXi0F4lxl3Q1IEvOMbS09N1ePc2/bFskZ4dOFppV1J1OTHBKU1MiLugwJC8VpQMNzl54rg2/LFe0R98aHUp8HA5/u5mu91umlpOTDEsqiZ7SDfSlZqSYnUZuEP+vl5KN5z/v5yWfnVpnGuuNYhF8wWoy/QNirvMtYg5VYmK1dXr/RlOY99MGa0CkYVVr/VTCs5XQN7ePjq440/dW/PqEldnTxxR3NnTKlzmXitKhpt8u/gb5Q0NVZ16DW99MFzGiyjRJMc3iZ5u4vgxqlOvgSIiIpSYmKgfvluqTRv+0KSp060uDXdo1e4z6tGohE7GJWn/qQSVjwxSp3pF9c2mq2ti+njZNO7pKiofEaRe8/6Ut5dN+QOvpuhxl1OVmubZvyzlNHb/3CpYuLjTmK/dT/55ghzj1Rs31w/zJss/MI/8/AP07awJKly6ggqXrmBFyXCD9PR0fbv4Gz3Sso18fPgnGtbKdv8PzMl3AVnh/PnzGvyfN3T2zBkF5smj0qXLatLU6apVp67VpeEODV+yW32iSmlQq/IKDby6mPaXfxzTlJ8PSJLCguxqUv7q9UoLX67j9NzO0zdowyFuZrjbPPxcL9m8vLRg7Du6ciVVpSrfp5bd+lpdFlxow+/rFRNzUi1bt7W6FI9D+2FmMwzDsrihbVvnPwRLlixRkyZNFBAQ4DS+cOHCTJ3X06ebPc0DQ5dbXQKy0ODHmVr1JE3LhFtdArJQaIC3Za/dzI1fQrDspZpuO7c7WZokBgcHOz1+5plnLKoEAAAA/2Rpkzhr1iwrXx4AAECS802BuIqv5QMAAIBJtrtxBQAAIKtx46wZSSIAAABMSBIBAIDHI0g0I0kEAACAiUuaxNjYWFecBgAAwBI2N/4vp8p0kzhq1CgtWLDA8bh9+/bKly+fChUqpK1bt7q0OAAAgKzgZXPfllNlukmcOnWqChcuLElavny5li9fru+//17NmzfXa6+95vICAQAAkPUyfeNKTEyMo0lcunSp2rdvr4ceekjFihVTzZo582tnAACAZ2MJHLNMJ4l58+bV0aNHJUk//PCDoqKiJEmGYSgtLc211QEAAMASmU4S27Ztq6efflqlS5fWuXPn1Lx5c0nS5s2bVapUKZcXCAAA4G4EiWaZbhLHjRunYsWK6ejRoxo9erQCAwMlSSdPntRLL73k8gIBAACQ9TLdJObKlUuvvvqqabxfv34uKQgAACCreRElmmSoSVy8eHGGT/joo4/edjEAAADIHjLUJLZp0yZDJ7PZbNy8AgAAchyCRLMMNYnp6enurgMAAMAyLIFjdkdfy5eUlOSqOgAAAJCNZLpJTEtL07vvvqtChQopMDBQBw8elCQNGjRIM2bMcHmBAAAA7mazuW/LqTLdJA4fPlyzZ8/W6NGj5evr6xivWLGipk+f7tLiAAAAYI1MN4lz587VtGnT1LFjR3l7ezvGq1Spot27d7u0OAAAgKzgZbO5bcupMt0kHj9+/IbfrJKenq7U1FSXFAUAAABrZbpJrFChgn755RfT+FdffaVq1aq5pCgAAICsZHPjllNl+htXBg8erE6dOun48eNKT0/XwoULtWfPHs2dO1dLly51R40AAADIYplOElu3bq0lS5bop59+UkBAgAYPHqxdu3ZpyZIlatq0qTtqBAAAcCubzea2LafKdJIoSfXr19fy5ctdXQsAAIAlvHJuL+c2t9UkStLGjRu1a9cuSVevU6xRo4bLigIAAIC1Mt0kHjt2TE899ZR+/fVXhYSESJJiY2NVp04dff7557rnnntcXSMAAIBb5eRpYXfJ9DWJ3bt3V2pqqnbt2qXz58/r/Pnz2rVrl9LT09W9e3d31AgAAIAslukkcfXq1Vq3bp3Kli3rGCtbtqwmTpyo+vXru7Q4AACArECQaJbpJLFw4cI3XDQ7LS1NkZGRLikKAAAA1sp0k/j+++/r5Zdf1saNGx1jGzdu1CuvvKIPPvjApcUBAABkBZbAMcvQdHPevHmd3mRiYqJq1qwpH5+rT79y5Yp8fHzUtWtXtWnTxi2FAgAAIOtkqEkcP368m8sAAACwDuskmmWoSezUqZO76wAAALBMTp4WdpfbXkxbkpKSkpSSkuI0FhQUdEcFAQAAwHqZvnElMTFRvXv3VlhYmAICApQ3b16nDQAAIKexuXHLqTLdJL7++utauXKlpkyZIrvdrunTp2vo0KGKjIzU3Llz3VEjAACAxzh+/LieeeYZ5cuXT/7+/qpUqZLTqjKGYWjw4MGKiIiQv7+/oqKitG/fPpfXkekmccmSJZo8ebLatWsnHx8f1a9fX2+//bZGjBihTz/91OUFAgAAuJuXzea2LTMuXLigunXrKleuXPr++++1c+dOjRkzxmm2dvTo0ZowYYKmTp2q33//XQEBAWrWrJmSkpJc+plk+prE8+fPq0SJEpKuXn94/vx5SVK9evXUs2dPlxYHAADgSUaNGqXChQtr1qxZjrHixYs7/tswDI0fP15vv/22WrduLUmaO3euChYsqEWLFqlDhw4uqyXTSWKJEiV06NAhSVK5cuX0xRdfSLqaMIaEhLisMAAAgKxis7lvS05OVnx8vNOWnJx8wzoWL16s++67T0888YTCwsJUrVo1ffzxx479hw4dUkxMjKKiohxjwcHBqlmzptavX+/SzyTTTWKXLl20detWSdKbb76pSZMmyc/PT/369dNrr73m0uIAAAByuujoaAUHBztt0dHRNzz24MGDmjJlikqXLq1ly5apZ8+e6tOnj+bMmSNJiomJkSQVLFjQ6XkFCxZ07HOVTE839+vXz/HfUVFR2r17tzZt2qRSpUqpcuXKLi0OAAAgK7hzncSBAweqf//+TmN2u/2Gx6anp+u+++7TiBEjJEnVqlXTjh07NHXq1CxftzrTSeL1ihYtqrZt2yo0NFQ9evRwRU0AAAB3DbvdrqCgIKftZk1iRESEKlSo4DRWvnx5HTlyRJIUHh4uSTp16pTTMadOnXLsc5U7bhKvOXfunGbMmOGq0wEAAGQZd16TmBl169bVnj17nMb27t2rokWLSrp6E0t4eLhWrFjh2B8fH6/ff/9dtWvXvuPP4Z/u6BtXAAAA7gaZXarGXfr166c6depoxIgRat++vf744w9NmzZN06ZNk3R1Wrxv37567733VLp0aRUvXlyDBg1SZGSk2rRp49JaaBIBAACyifvvv1/ffPONBg4cqGHDhql48eIaP368Onbs6Djm9ddfV2Jionr06KHY2FjVq1dPP/zwg/z8/FxaC00iAADweNkkSJQktWzZUi1btrzpfpvNpmHDhmnYsGFurSPDTWLbtm3/dX9sbOyd1gIAAIBsIsNNYnBw8C33P/fcc3dcEAAAQFZz5xI4OVWGm8R/fj0MAAAA7m5ck4gc77v+Da0uAVmoXNQAq0tAFpo9c6DVJSALPVmtkGWv7bI1Ae8ifCYAAAAwIUkEAAAej2sSzWgSAQCAx/OiRzRhuhkAAAAmGUoSFy9enOETPvroo7ddDAAAgBVIEs0y1CRm9LsAbTab0tLS7qQeAAAAZAMZahLT09PdXQcAAIBluHHFjGsSAQAAYHJbdzcnJiZq9erVOnLkiFJSUpz29enTxyWFAQAAZBWuSTTLdJO4efNmPfLII7p06ZISExMVGhqqs2fPKnfu3AoLC6NJBAAAuAtkerq5X79+atWqlS5cuCB/f3/99ttvOnz4sGrUqKEPPvjAHTUCAAC4lc3mvi2nynSTuGXLFg0YMEBeXl7y9vZWcnKyChcurNGjR+utt95yR40AAABu5WWzuW3LqTLdJObKlUteXlefFhYWpiNHjkiSgoODdfToUddWBwAAAEtk+prEatWqacOGDSpdurQaNmyowYMH6+zZs5o3b54qVqzojhoBAADciuVezDL9mYwYMUIRERGSpOHDhytv3rzq2bOnzpw5o2nTprm8QAAAAGS9TCeJ9913n+O/w8LC9MMPP7i0IAAAgKyWgy8ddBvSVQAAAJhkOkksXrz4v351zcGDB++oIAAAgKyWk+9CdpdMN4l9+/Z1epyamqrNmzfrhx9+0GuvveaqugAAAGChTDeJr7zyyg3HJ02apI0bN95xQQAAAFmNINHMZdckNm/eXF9//bWrTgcAAJBlvGzu23IqlzWJX331lUJDQ111OgAAAFjothbT/ueNK4ZhKCYmRmfOnNHkyZNdWhwAAEBW4MYVs0w3ia1bt3ZqEr28vFSgQAE1atRI5cqVc2lxAAAAsEamm8R33nnHDWUAAABYhyDRLNPXJHp7e+v06dOm8XPnzsnb29slRQEAAMBamU4SDcO44XhycrJ8fX3vuCAAAICslpPvQnaXDDeJEyZMkCTZbDZNnz5dgYGBjn1paWlas2YN1yQCAADcJTLcJI4bN07S1SRx6tSpTlPLvr6+KlasmKZOner6CgEAANzMJqLE62W4STx06JAkqXHjxlq4cKHy5s3rtqIAAACyEtPNZpm+JvHnn392Rx0AAADIRjJ9d3O7du00atQo0/jo0aP1xBNPuKQoAACArMTX8plluklcs2aNHnnkEdN48+bNtWbNGpcUBQAAAGtlero5ISHhhkvd5MqVS/Hx8S4pCgAAICvZWE3bJNNJYqVKlbRgwQLT+Oeff64KFSq4pCgAAABYK9NJ4qBBg9S2bVsdOHBATZo0kSStWLFC8+fP15dffunyAgEAANwtJ1876C6ZbhJbtWqlRYsWacSIEfrqq6/k7++vypUr66efflLDhg3dUSMAAACyWKabRElq0aKFWrRoYRrfsWOHKlaseMdFAQAAZCUuSTTL9DWJ17t48aKmTZumBx54QFWqVHFFTQAAAFnKy2Zz25ZT3XaTuGbNGj333HOKiIjQBx98oCZNmui3335zZW0AAACwSKamm2NiYjR79mzNmDFD8fHxat++vZKTk7Vo0SLubAYAADkWN66YZThJbNWqlcqWLatt27Zp/PjxOnHihCZOnOjO2gAAAGCRDCeJ33//vfr06aOePXuqdOnS7qwJAAAgS+XgSwfdJsNJ4tq1a3Xx4kXVqFFDNWvW1EcffaSzZ8+6szYAAABYJMNNYq1atfTxxx/r5MmTeuGFF/T5558rMjJS6enpWr58uS5evOjOOgEAANzGSza3bTlVpu9uDggIUNeuXbV27Vpt375dAwYM0MiRIxUWFqZHH33UHTUCAAAgi93ROolly5bV6NGjdezYMc2fP99VNQEAAGQpm819W051W9+4cj1vb2+1adNGbdq0ccXpAAAAshRL4Jjd8TeuAAAA4O7jkiQRAAAgJ8vJX5/nLiSJAAAAMKFJzOG+XDBf7ds+qvq1aqh+rRrq1PFJ/frLGqvLgots27xRg17rrQ6PPqiH6lTWr6tX3vTYD0e/q4fqVNbCBfOysELcibrVS+qr8S/o4I/DdXnzR2rVqLLT/tZNqmjJ5F469vMoXd78kSqXKfSv51v0Uc8bngfZ35r/fabBHZrouzkfOcZSU1K0dOaHiu7eRu91ekSfjx2ihNjzFlZ5d+PGFTOaxBwurGBB9ek7QJ8u+FqffP6V7q9ZS/369NKB/fusLg0ukJR0WSVKlVXvAW/963FrV6/Qrr+2KV/+sCyqDK4Q4G/X9r3H1Td6wQ335/b31botB/T2hEW3PNfLHRvLMFxcILLE8QO7tfGnpSpYpITT+A9zJ2nPpvV6su9gdR0yXvEXzmn+2CEWVQlPxDWJOVzDRk2cHvfu009fLfhc27dtVclSfH1iTvdA7fp6oHb9fz3m7JlTmjw2WiPGTdWgV3tnUWVwhR9/3akff9150/3zv90gSSoSEfqv56lcppBeebaJ6nYcrb9/inZpjXCv5KTL+mriCLXuMUCrF37iGE+6lKA/f/5ej7/8H5WoWF2S9NiLr2vigM46um+nCpeuYFXJdy2uSTQjSbyLpKWladn33+ry5UuqXKWq1eUgC6Snp2vU0Lf0xNOdVaxEKavLgQX8/XJpdnRn9R35hU6d45uvcppvZ36oMtVqqmSlGk7jJw7uVVraFZX4x3iBQkUUnD9MR/f+ldVlwkNZmiR6eXnJdovO3Waz6cqVKzfdn5ycrOTkZKexKzZf2e12l9SYE+zbu0edn3lKKSnJ8s+dW2PGf6QSJWkYPMGCT2bK29tHbdp3tLoUWGT0gHb6beshLV213epSkEnb163UiUP79MLwKaZ9CbEX5O2TS/4BgU7jgcF5lRB7IatK9CgEiWaWNonffPPNTfetX79eEyZMUHp6+r+eIzo6WkOHDnUaG/j2YP1n0DuuKDFHKFa8uOZ/9Y0SLl7UiuXLNPjtNzV91jwaxbvc3t07teiLTzV51oJb/rKFu1OLhpXU6IEyqtVhpNWlIJPizp7Wd3MmqdNbo5XL19fqciCmVm/E0iaxdevWprE9e/bozTff1JIlS9SxY0cNGzbsX88xcOBA9e/f32nsis2z/sDlyuWrIkWKSpIq3FtRf+3Yoc8+mau3h/z7Z4ecbcfWTYq9cF4d2zZzjKWnpWnaxDH6ZsGnmrfwBwurQ1ZodH8Zlbgnv2LWvO80Pv+D7vp18wE1e/5DiyrDrZw4tFeJcRc0deALjrH09HQd3r1NfyxbpGcHjlbalVRdTkxwShMT4i4oMCSvFSXDA2WbG1dOnDihIUOGaM6cOWrWrJm2bNmiihUr3vJ5drvdNLWcmOLZt/ilG+lKTUmxugy4WdTDrVTtvlpOY2/166moh1vqoRbmX8Bw9/lg1o+a9c06p7FNX/1Hr4/5Wt+u3mFRVciIEhWrq9f7M5zGvpkyWgUiC6te66cUnK+AvL19dHDHn7q3ZgNJ0tkTRxR39rQKl7nXipLveszImFneJMbFxWnEiBGaOHGiqlatqhUrVqh+/X+/mxP/Z+L4MapTr4EiIiKUmJioH75bqk0b/tCkqdOtLg0ucPnSJZ04dsTxOObkcR3Yu1t5goIVFh6hoOAQp+N9fHyUN18+FS5aPIsrxe0I8PdVycIFHI+LFcqnymUK6UL8JR2NuaC8QblVODyvIsKCJUllihWUJJ06F69T5y46tusdPXlBh0+cy5o3gdti98+tgoWd/5z62v3knyfIMV69cXP9MG+y/APzyM8/QN/OmqDCpStwZzOyjKVN4ujRozVq1CiFh4dr/vz5N5x+xr87f/68Bv/nDZ09c0aBefKodOmymjR1umrVqWt1aXCBvbv/0mu9uzke/3fC1WnFpo88qtfefs+qsuAi1SsU1Y/TX3E8Hv1qO0nSvMW/qceQT9SiYSV9POxZx/55o7pKkt6b+p2G//e7rC0WWe7h53rJ5uWlBWPf0ZUrqSpV+T617NbX6rLuWuSIZjbDsG75VS8vL/n7+ysqKkre3t43PW7hwoWZOq+nTzd7mrMXmVr3JOWiBlhdArLQ7JkDrS4BWejJav/+rULuNHfjUbed+7n7Crvt3O5kaZL43HPPcQ0AAACwHItpm1naJM6ePdvKlwcAAMBNWH7jCgAAgNXIEc1oEgEAgMdjttmMBcYBAACyqZEjR8pms6lv376OsaSkJPXq1Uv58uVTYGCg2rVrp1OnTrn8tWkSAQCAx7PZbG7bbteGDRv03//+V5UrV3Ya79evn5YsWaIvv/xSq1ev1okTJ9S2bds7/QhMaBIBAACymYSEBHXs2FEff/yx8ub9v69ijIuL04wZMzR27Fg1adJENWrU0KxZs7Ru3Tr99ttvLq2BJhEAAHg8LzduycnJio+Pd9qSk5P/tZ5evXqpRYsWioqKchrftGmTUlNTncbLlSunIkWKaP369Xf2IVyHJhEAAMCNoqOjFRwc7LRFR0ff9PjPP/9cf/755w2PiYmJka+vr0JCQpzGCxYsqJiYGJfWzd3NAADA47nzyz0GDhyo/v37O43Z7fYbHnv06FG98sorWr58ufz8/NxWU0bQJAIAALiR3W6/aVN4vU2bNun06dOqXr26YywtLU1r1qzRRx99pGXLliklJUWxsbFOaeKpU6cUHh7u0rppEgEAgMfLLsskPvjgg9q+fbvTWJcuXVSuXDm98cYbKly4sHLlyqUVK1aoXbt2kqQ9e/boyJEjql27tktroUkEAADIJvLkyaOKFSs6jQUEBChfvnyO8W7duql///4KDQ1VUFCQXn75ZdWuXVu1atVyaS00iQAAwOO585pEVxs3bpy8vLzUrl07JScnq1mzZpo8ebLLX4cmEQAAeLzsvNzLqlWrnB77+flp0qRJmjRpkltfNzt/JgAAALAISSIAAPB4OWm6OauQJAIAAMCEJBEAAHg8ckQzkkQAAACYkCQCAACPxyWJZiSJAAAAMCFJBAAAHs+LqxJNaBIBAIDHY7rZjOlmAAAAmJAkAgAAj2djutmEJBEAAAAmJIkAAMDjcU2iGUkiAAAATEgSAQCAx2MJHDOSRAAAAJiQJAIAAI/HNYlmNIkAAMDj0SSaMd0MAAAAE5JEAADg8VhM24wkEQAAACYkiQAAwON5ESSakCQCAADAhCQRAAB4PK5JNCNJBAAAgAlJIgAA8Hisk2hGkwgAADwe081mTDcDAADAhCQRAAB4PJbAMSNJBAAAgAlJIgAA8Hhck2hGkggAAAATkkQAAODxWALHjCQRAAAAJiSJAADA4xEkmtEkAgAAj+fFfLMJ080AAAAwuSuTRH4Z8CwFg+1Wl4AstH3Z+1aXgCw0du0hq0tAFnqyWiHLXpvWwYwkEQAAACZ3ZZIIAACQKUSJJiSJAAAAMCFJBAAAHo+v5TMjSQQAAIAJSSIAAPB4rIxiRpMIAAA8Hj2iGdPNAAAAMCFJBAAAIEo0IUkEAACACUkiAADweCyBY0aSCAAAABOSRAAA4PFYAseMJBEAAAAmJIkAAMDjESSa0SQCAADQJZow3QwAAAATkkQAAODxWALHjCQRAAAAJiSJAADA47EEjhlJIgAAAExIEgEAgMcjSDQjSQQAAIAJSSIAAABRoglNIgAA8HgsgWPGdDMAAABMSBIBAIDHYwkcM5JEAAAAmJAkAgAAj0eQaEaSCAAAABOSRAAAAKJEE5JEAAAAmJAkAgAAj8c6iWYkiQAAANlEdHS07r//fuXJk0dhYWFq06aN9uzZ43RMUlKSevXqpXz58ikwMFDt2rXTqVOnXF4LTSIAAPB4Npv7tsxYvXq1evXqpd9++03Lly9XamqqHnroISUmJjqO6devn5YsWaIvv/xSq1ev1okTJ9S2bVsXfyKSzTAMw+Vntdil1LvuLeFfeLECqkc5dv6y1SUgC41de8jqEpCFJretYNlr7zqReOuDblP5yIDbfu6ZM2cUFham1atXq0GDBoqLi1OBAgX02Wef6fHHH5ck7d69W+XLl9f69etVq1YtV5VNkggAAOBOycnJio+Pd9qSk5Mz9Ny4uDhJUmhoqCRp06ZNSk1NVVRUlOOYcuXKqUiRIlq/fr1L66ZJBAAAsLlvi46OVnBwsNMWHR19y5LS09PVt29f1a1bVxUrVpQkxcTEyNfXVyEhIU7HFixYUDExMXf2GVyHu5sBAADcaODAgerfv7/TmN1uv+XzevXqpR07dmjt2rXuKu1f0SQCAACP584lcOx2e4aawn/q3bu3li5dqjVr1uiee+5xjIeHhyslJUWxsbFOaeKpU6cUHh7uqpIlMd0MAACQbRiGod69e+ubb77RypUrVbx4caf9NWrUUK5cubRixQrH2J49e3TkyBHVrl3bpbWQJAIAAI+XXRbK6NWrlz777DP973//U548eRzXGQYHB8vf31/BwcHq1q2b+vfvr9DQUAUFBenll19W7dq1XXpns0STCAAAkG1MmTJFktSoUSOn8VmzZqlz586SpHHjxsnLy0vt2rVTcnKymjVrpsmTJ7u8FtZJRI7HOomehXUSPQvrJHoWK9dJ3BtzyW3nLhOe223ndieSRAAAAPIGE25cAQAAgAlJIgAA8HjuXAInpyJJBAAAgAlJIgAA8HjcA2lGkggAAAATkkQAAODxCBLNSBIBAABgQpKYw834+L9a+dNy/X3ooOx+fqpStZpe6TdAxYqXsLo0uMGmjRs0e+YM7dq5Q2fOnNG4CZPU5MEoq8uCi+zYsklfz5+j/Xt26fy5M3p7+FjVbtDEsb9F/ao3fF7Xnn3V7unOWVMkXKZF+QJqUb6A01jMxWQNW35AkhRk99ZjlQqqXFig/Hy8dCohWT/sPqstJy5aUe7djyjRhCYxh/tz4wY9+dTTurdiJV25kqaPPhynnj26a+H/lso/d85c4R03d/nyJZUtW1Zt2rZT/1d6W10OXCwp6bKKlyqjpi3aaPh/+pv2z1v0k9PjTb+t1YejhqpOI35RyKlOxCVpwtrDjsdp//jCsE73FZJ/Lm9NXX9ECclpur9wsLrXvEcjVx7SsbgkC6q9u7EEjhlNYg436b/TnR4PHR6tBxvU0c6df6nGffdbVBXcpV79hqpXv6HVZcBN7qtVT/fVqnfT/aH58js9/m3tKlWudr8iIu9xd2lwkzRDik9Ou+G+4vly6/PNJ3X4wtWG8Ic9Z9WkVKiK5PWjSUSWsOyaxPXr12vp0qVOY3PnzlXx4sUVFhamHj16KDk52aLqcq6EhKvTEMHBwRZXAsCdLpw/pw3r1+qhlm2sLgV3ICzQVyOal9awZqXU+b5Cyuv/f9nNoXOXVOOeIOXO5SWbpBr3BCmXt5f2nUm0ruC7mM3mvi2nsqxJHDZsmP766y/H4+3bt6tbt26KiorSm2++qSVLlig6OvqW50lOTlZ8fLzT5qnNZXp6uj4YOUJVq1VXqdJlrC4HgBut+H6x/HPnVp0GD1pdCm7TofOXNXfTcU369Yjmbz6p/AG51L9hMdl9rv7TPP2PY/L2sumDVuU0oU15PV0tQtN+O6oziakWVw5PYVmTuGXLFj344P/95fb555+rZs2a+vjjj9W/f39NmDBBX3zxxS3PEx0dreDgYKftg1G3bi7vRtHvDdP+/fs08v2xVpcCwM2Wf/c/NWr6iHztdqtLwW3aeSpBm49f1PH4ZO06nahJ644ody5v1SgUJElqVSFM/rm89eEvhzXy54Nase+cuj1wjyKD+Jm7g82NW05lWZN44cIFFSxY0PF49erVat68uePx/fffr6NHj97yPAMHDlRcXJzT9uobA91Sc3Y2cvgw/bJ6lT6eOVcFw8OtLgeAG+3Y+qeOHflbzVo9ZnUpcKHLqek6nZCiAoG+yh+QS41KhuqTTSe050yijscl67vdZ3Uk9rIalshrdanwEJY1iQULFtShQ4ckSSkpKfrzzz9Vq1Ytx/6LFy8qV65ctzyP3W5XUFCQ02b3oN+sDcPQyOHDtHLFT/rvzNkqdA8XsAN3ux+XfqNSZSuoRKmyVpcCF7J725Q/wFdxSVfk6331n2dDhtMx6YZky8kXuWVnRIkmlt3d/Mgjj+jNN9/UqFGjtGjRIuXOnVv169d37N+2bZtKlixpVXk5RvR7w/T9d0s1bsIkBQQE6OzZM5KkwMA88vPzs7g6uNqlxEQdOXLE8fj4sWPavWuXgoODFREZaWFlcIXLly7pxPH/+/nGnDyuA/t2K09QsMIKRkiSLiUmaO2q5erea4BVZcJF2lYsqO0xF3XuUqpC/HzUonwBpRuGNh6N06XUNJ1OSNZT1SK0cPspJaakqUpEHpULC9CUdbeeZQNcwWYYhnHrw1zv7Nmzatu2rdauXavAwEDNmTNHjz32f1MnDz74oGrVqqXhw4dn+tyXUi15S5aoVrHcDceHvjdCj7Zpm8XVWMPLg36r3vDH7+re5TnT+KOtH9O7I0ZaUFHWO3b+stUluM22zRs0sM/zpvEHH26l/v95V5L0/eKv9PGEDzRv0XIFBObJ6hKz3Ni1h6wuwW263l9IpfLnVoCvtxJS0nTg7CUt3nlaZ///jSkFAnzVpmKYSubLLbuPl84kpOinfef0x9E4iyt3n8ltK1j22ofPue+m16L5cuYMp2VN4jVxcXEKDAyUt7e30/j58+cVGBgoX1/fTJ/Tk5pEeFaTiLu7SYTZ3dwkwszKJvHIefc1iUVCc2aTaPli2jdbzy80NDSLKwEAAMA1ljeJAAAAVmNOysyyu5sBAACQfZEkAgAAj8fl7WYkiQAAADAhSQQAAOCqRBOSRAAAAJiQJAIAAI/HNYlmNIkAAMDj0SOaMd0MAAAAE5JEAADg8ZhuNiNJBAAAgAlJIgAA8Hg2rko0IUkEAACACUkiAAAAQaIJSSIAAABMSBIBAIDHI0g0o0kEAAAejyVwzJhuBgAAgAlJIgAA8HgsgWNGkggAAAATkkQAAACCRBOSRAAAAJiQJAIAAI9HkGhGkggAAAATkkQAAODxWCfRjCYRAAB4PJbAMWO6GQAAACYkiQAAwOMx3WxGkggAAAATmkQAAACY0CQCAADAhGsSAQCAx+OaRDOSRAAAAJiQJAIAAI/HOolmNIkAAMDjMd1sxnQzAAAATEgSAQCAxyNINCNJBAAAgAlJIgAAAFGiCUkiAAAATEgSAQCAx2MJHDOSRAAAAJiQJAIAAI/HOolmJIkAAAAwIUkEAAAejyDRjCYRAACALtGE6WYAAACYkCQCAACPxxI4ZiSJAAAAMCFJBAAAHo8lcMxIEgEAAGBiMwzDsLoI3Lnk5GRFR0dr4MCBstvtVpcDN+Pn7Vn4eXsWft7ILmgS7xLx8fEKDg5WXFycgoKCrC4HbsbP27Pw8/Ys/LyRXTDdDAAAABOaRAAAAJjQJAIAAMCEJvEuYbfbNWTIEC5y9hD8vD0LP2/Pws8b2QU3rgAAAMCEJBEAAAAmNIkAAAAwoUkEAACACU0iAAAATGgS7xLr16+Xt7e3WrRoYXUpcJPOnTurTZs2pvFVq1bJZrMpNjY2y2uC+3Tu3Fk2m00jR450Gl+0aJFsNptFVcHdzpw5o549e6pIkSKy2+0KDw9Xs2bN9Ouvv1pdGjwQTeJdYsaMGXr55Ze1Zs0anThxwupyALiAn5+fRo0apQsXLlhdCrJIu3bttHnzZs2ZM0d79+7V4sWL1ahRI507d87q0uCBfKwuAHcuISFBCxYs0MaNGxUTE6PZs2frrbfesrosAHcoKipK+/fvV3R0tEaPHm11OXCz2NhY/fLLL1q1apUaNmwoSSpatKgeeOABiyuDpyJJvAt88cUXKleunMqWLatnnnlGM2fOFMtfAjmft7e3RowYoYkTJ+rYsWNWlwM3CwwMVGBgoBYtWqTk5GSrywFoEu8GM2bM0DPPPCNJevjhhxUXF6fVq1dbXBXcYenSpY5/SK5tzZs3t7osuNFjjz2mqlWrasiQIVaXAjfz8fHR7NmzNWfOHIWEhKhu3bp66623tG3bNqtLg4eiSczh9uzZoz/++ENPPfWUpKt/yTz55JOaMWOGxZXBHRo3bqwtW7Y4bdOnT7e6LLjZqFGjNGfOHO3atcvqUuBm7dq104kTJ7R48WI9/PDDWrVqlapXr67Zs2dbXRo8EE1iDjdjxgxduXJFkZGR8vHxkY+Pj6ZMmaKvv/5acXFxVpcHFwsICFCpUqWctkKFClldFtysQYMGatasmQYOHGh1KcgCfn5+atq0qQYNGqR169apc+fOJMmwBE1iDnblyhXNnTtXY8aMcUqWtm7dqsjISM2fP9/qEgG4yMiRI7VkyRKtX7/e6lKQxSpUqKDExESry4AH4u7mHGzp0qW6cOGCunXrpuDgYKd97dq104wZM/Tiiy9aVB0AV6pUqZI6duyoCRMmWF0K3OTcuXN64okn1LVrV1WuXFl58uTRxo0bNXr0aLVu3drq8uCBSBJzsBkzZigqKsrUIEpXm8SNGzdywTNwFxk2bJjS09OtLgNuEhgYqJo1a2rcuHFq0KCBKlasqEGDBun555/XRx99ZHV58EA2g7VSAAAAcB2SRAAAAJjQJAIAAMCEJhEAAAAmNIkAAAAwoUkEAACACU0iAAAATGgSAQAAYEKTCAAAABOaRAC3rXPnzmrTpo3jcaNGjdS3b98sr2PVqlWy2WyKjY1122tc/15vR1bUCQCuQpMI3GU6d+4sm80mm80mX19flSpVSsOGDdOVK1fc/toLFy7Uu+++m6Fjs7phKlasmMaPH58lrwUAdwMfqwsA4HoPP/ywZs2apeTkZH333Xfq1auXcuXKpYEDB5qOTUlJka+vr0teNzQ01CXnAQBYjyQRuAvZ7XaFh4eraNGi6tmzp6KiorR48WJJ/zdtOnz4cEVGRqps2bKSpKNHj6p9+/YKCQlRaGioWrdurb///ttxzrS0NPXv318hISHKly+fXn/9dV3/1e/XTzcnJyfrjTfeUOHChWW321WqVCnNmDFDf//9txo3bixJyps3r2w2mzp37ixJSk9PV3R0tIoXLy5/f39VqVJFX331ldPrfPfddypTpoz8/f3VuHFjpzpvR1pamrp16+Z4zbJly+rDDz+84bFDhw5VgQIFFBQUpBdffFEpKSmOfRmp/Z8OHz6sVq1aKW/evAoICNC9996r77777o7eCwC4Ckki4AH8/f117tw5x+MVK1YoKChIy5cvlySlpqaqWbNmql27tn755Rf5+Pjovffe08MPP6xt27bJ19dXY8aM0ezZszVz5kyVL19eY8aM0TfffKMmTZrc9HWfe+45rV+/XhMmTFCVKlV06NAhnT17VoULF9bXX3+tdu3aac+ePQoKCpK/v78kKTo6Wp988ommTp2q0qVLa82aNXrmmWdUoEABNWzYUEePHlXbtm3Vq1cv9ejRQxs3btSAAQPu6PNJT0/XPffcoy+//FL58uXTunXr1KNHD0VERKh9+/ZOn5ufn59WrVqlv//+W126dFG+fPk0fPjwDNV+vV69eiklJUVr1qxRQECAdu7cqcDAwDt6LwDgMgaAu0qnTp2M1q1bG4ZhGOnp6cby5csNu91uvPrqq479BQsWNJKTkx3PmTdvnlG2bFkjPT3dMZacnGz4+/sby5YtMwzDMCIiIozRo0c79qemphr33HOP47UMwzAaNmxovPLKK4ZhGMaePXsMScby5ctvWOfPP/9sSDIuXLjgGEtKSjJy585trFu3zunYbt26GU899ZRhGIYxcOBAo0KFCk7733jjDdO5rle0aFFj3LhxN91/vV69ehnt2rVzPO7UqZMRGhpqJCYmOsamTJliBAYGGmlpaRmq/fr3XKlSJeOdd97JcE0AkJVIEoG70NKlSxUYGKjU1FSlp6fr6aef1jvvvOPYX6lSJafrELdu3ar9+/crT548TudJSkrSgQMHFBcXp5MnT6pmzZqOfT4+PrrvvvtMU87XbNmyRd7e3jdM0G5m//79unTpkpo2beo0npKSomrVqkmSdu3a5VSHJNWuXTvDr3EzkyZN0syZM3XkyBFdvnxZKSkpqlq1qtMxVapUUe7cuZ1eNyEhQUePHlVCQsIta79enz591LNnT/3444+KiopSu3btVLly5Tt+LwDgCjSJwF2ocePGmjJlinx9fRUZGSkfH+c/6gEBAU6PExISVKNGDX366aemcxUoUOC2arg2fZwZCQkJkqRvv/1WhQoVctpnt9tvq46M+Pzzz/Xqq69qzJgxql27tvLkyaP3339fv//+e4bPcTu1d+/eXc2aNdO3336rH3/8UdHR0RozZoxefvnl238zAOAiNInAXSggIEClSpXK8PHVq1fXggULFBYWpqCgoBseExERod9//10NGjSQJF25ckWbNm1S9erVb3h8pUqVlJ6ertWrVysqKsq0/1qSmZaW5hirUKGC7Ha7jhw5ctMEsnz58o6bcK757bffbv0m/8Wvv/6qOnXq6KWXXnKMHThwwHTc1q1bdfnyZUcD/NtvvykwMFCFCxdWaGjoLWu/kcKFC+vFF1/Uiy++qIEDB+rjjz+mSQSQLXB3MwB17NhR+fPnV+vWrfXLL7/o0KFDWrVqlfr06aNjx45Jkl555RWNHDlSixYt0u7du/XSSy/96xqHxYoVU6dOndS1a1ctWrTIcc4vvvhCklS0aFHZbDYtXbpUZ86cUUJCgvLkyaNXX31V/fr105w5c3TgwAH9+eefmjhxoubMmSNJevHFF7Vv3z699tpr2rNnjz777DPNnj07Q+/z+PHj2rJli9N24cIFlS5dWhs3btSyZcu0d+9eDRo0SBs2bDA9PyUlRd26ddPOnTv13XffaciQIerdu7e8vLwyVPv1+vbtq2XLlunQoUP6888/9fPPP6t8+fIZei8A4HZWXxQJwLX+eeNKZvafPHnSeO6554z8+fMbdrvdKFGihPH8888bcXFxhmFcvVHllVdeMYKCgoyQkBCjf//+xnPPPXfTG1cMwzAuX75s9OvXz4iIiDB8fX2NUqVKGTNnznTsHzZsmBEeHm7YbDajU6dOhmFcvdlm/PjxRtmyZY1cuXIZBQoUMJo1a2asXr3a8bwlS5YYpUqVMux2u1G/fn1j5syZGbpxRZJpmzdvnpGUlGR07tzZCA4ONkJCQoyePXsab775plGlShXT5zZ48GAjX758RmBgoPH8888bSUlJjmNuVfv1N6707t3bKFmypGG3240CBQoYzz77rHH27NmbvgcAyEo2w7jJVecAAADwWEw3AwAAwIQmEQAAACY0iQAAADChSQQAAIAJTSIAAABMaBIBAABgQpMIAAAAE5pEAAAAmNAkAgAAwIQmEQAAACY0iQAAADD5f6nR6Cgj7mKgAAAAAElFTkSuQmCC"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Accuracy: 0.6818181818181818\ntest UA: 0.6881392417106703\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           A       0.93      0.72      0.81       147\n           H       0.76      0.62      0.68       132\n           N       0.57      0.67      0.61       171\n           S       0.55      0.74      0.63        78\n\n    accuracy                           0.68       528\n   macro avg       0.70      0.69      0.69       528\nweighted avg       0.71      0.68      0.69       528\n\n",
          "output_type": "stream"
        }
      ],
      "id": "bkkSsZic0dX6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Previous Attempts and Methods"
      ],
      "metadata": {
        "id": "I_I3rxN9JaaR"
      },
      "id": "I_I3rxN9JaaR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Orginial Model before pretrained\n",
        "###Simplified version from \"3-D Convolutional Recurrent Neural Networks With Attention Model for Speech Emotion Recognition\"\n",
        "\n",
        "![altertext](https://drive.google.com/uc?id=1bHrsMSjWKf1XgmCshPrSU81fVSsNhfP4)\n",
        "\n",
        "[Paper link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8421023&casa_token=AGqWGVSS5lAAAAAA:cM6X58aNcHVZmsVC1r_ZxawguzlzMHMhxZzsLdxdYf7ogidcBmUmMHhgwKH6H33TGBGRXV1XUQYo0A&tag=1)\n",
        "\n",
        "[Github link](https://github.com/xuanjihe/speech-emotion-recognition/tree/master)"
      ],
      "metadata": {
        "id": "yqEADvpLHDtu"
      },
      "id": "yqEADvpLHDtu"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Orignial Model (before pretrained)\n",
        "# Import necessary libraries\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import soundfile as sound\n",
        "import datetime\n",
        "import sys, subprocess\n",
        "import math\n",
        "import random\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR, ExponentialLR, CosineAnnealingLR\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report, recall_score\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torchaudio import functional as audioF\n",
        "from torchaudio.compliance import kaldi\n",
        "\n",
        "def setup_seed(seed=2021):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "class Pad_trunc_wav(nn.Module):\n",
        "    def __init__(self, max_len: int = 6*16000):\n",
        "        super(Pad_trunc_wav, self).__init__()\n",
        "        self.max_len = max_len\n",
        "    def forward(self,x):\n",
        "        shape = x.shape\n",
        "        length = shape[1]\n",
        "        if length < self.max_len:\n",
        "            multiple = self.max_len//length+1\n",
        "            x_tmp = torch.cat((x,)*multiple, axis=1)\n",
        "            x_new = x_tmp[:,0:self.max_len]\n",
        "        else:\n",
        "            x_new = x[:,0:self.max_len]\n",
        "        return x_new\n",
        "\n",
        "class Deltas_Deltas_FBank(nn.Module):\n",
        "    #(…, freq, time)\n",
        "    def __init__(self):\n",
        "        super(Deltas_Deltas_FBank, self).__init__()\n",
        "    def forward(self,x):\n",
        "        # x: time*freq\n",
        "        x = x.permute(1,0).unsqueeze(0)\n",
        "        delta = audioF.compute_deltas(x)\n",
        "        delta2 = audioF.compute_deltas(delta)\n",
        "        x_out = torch.cat((x,delta,delta2), 0).permute(0,2,1)\n",
        "        # x_out: 3*freq*time -> 3*time*freq\n",
        "        return x_out\n",
        "\n",
        "!pip install audiomentations\n",
        "\n",
        "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, ClippingDistortion, Gain\n",
        "# Define a composite augmentation object with multiple augmentations applied sequentially\n",
        "augment = Compose([\n",
        "    # This augmentation adds Gaussian noise to the audio signal.\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "\n",
        "    # This augmentation changes the pitch of the audio signal by shifting it up or down by a random number of semitones within the specified range.\n",
        "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "\n",
        "    # This augmentation changes the tempo of the audio signal by stretching or compressing it.\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "\n",
        "    # This augmentation simulates clipping distortion by applying a random threshold (in percentile) to the audio signal\n",
        "    ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=10, p=0.4),\n",
        "\n",
        "    # This augmentation adjusts the volume (gain) of the audio signal by applying a random gain factor within the specified range.\n",
        "    Gain(min_gain_in_db=-6, max_gain_in_db=6, p=0.5),\n",
        "\n",
        "])\n",
        "\n",
        "class Mydataset(Dataset):\n",
        "    def __init__(self, mode='train', max_len=6, seed=42):\n",
        "        self.mode = mode\n",
        "        data_all = pd.read_csv('small-project/small-project/IEMOCAP_4.tsv',sep='\\t')\n",
        "        SpkNames = np.unique(data_all['speaker']) # only 10 speakers, (['Ses01F', 'Ses01M', 'Ses02F', 'Ses02M', 'Ses03F', 'Ses03M','Ses04F', 'Ses04M', 'Ses05F', 'Ses05M']\n",
        "        self.data_info = self.split_dataset(data_all, SpkNames)\n",
        "        self.get_audio_dir_path = os.path.join('small-project/small-project/IEMOCAP_full_release_audio/')\n",
        "        self.pad_trunc = Pad_trunc_wav(max_len*16000)\n",
        "        self.transform = Deltas_Deltas_FBank()\n",
        "        # label is emotion type:  A: Angry  H: Happy, N: Natural, S: Sad\n",
        "        self.label = self.data_info['label'].astype('category').cat.codes.values\n",
        "\n",
        "        self.ClassNames = np.unique(self.data_info['label'])\n",
        "        self.NumClasses = len(self.ClassNames)\n",
        "        if mode == 'train':\n",
        "          print(\"Each emotion has the following number of training samples:\")\n",
        "          print([[self.ClassNames[i], (self.label == i).sum()] for i in range(self.NumClasses)])\n",
        "        self.weight = 1/torch.tensor([(self.label==i).sum() for i in range(self.NumClasses)]).float()\n",
        "\n",
        "    def get_classname(self):\n",
        "        return  self.ClassNames\n",
        "\n",
        "    def split_dataset(self, df_all, speakers):\n",
        "        spk_len = len(speakers)\n",
        "        test_idx = np.array(df_all['speaker']==speakers[0]) # audio from 'Ses01F' as test set\n",
        "        val_idx = np.array(df_all['speaker']==speakers[1]) #  audio from 'Ses01M' as val set\n",
        "        train_idx = True^(test_idx+val_idx)\n",
        "        train_data_info = df_all[train_idx].reset_index(drop=True)\n",
        "        val_data_info = df_all[val_idx].reset_index(drop=True)\n",
        "        test_data_info = df_all[test_idx].reset_index(drop=True)\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            data_info = train_data_info\n",
        "        elif self.mode == 'val':\n",
        "            data_info = val_data_info\n",
        "        elif self.mode == 'test':\n",
        "            data_info = test_data_info\n",
        "        else:\n",
        "            data_info = df_all\n",
        "        return data_info\n",
        "\n",
        "    def pre_process(self, wav): #updated!!\n",
        "        # Normalize the waveform\n",
        "        if torch.max(torch.abs(wav)) != 0:\n",
        "            wav = wav / torch.max(torch.abs(wav)) # Normalize to [-1, 1] range\n",
        "        wav = self.pad_trunc(wav)  # Pad or truncate the waveform to the desired length\n",
        "        return wav\n",
        "\n",
        "    def extract_fbank(self, wav, sample_rate):\n",
        "        wav = wav * (1 << 15)\n",
        "        if sample_rate!=16000:\n",
        "            # if sample rate is not 16k, change (transform) to 16k\n",
        "            wav = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(wav)\n",
        "        # Extract Raw Fbank feature, the Fbank feature dimension is 80\n",
        "        spec = kaldi.fbank(wav,num_mel_bins=80,frame_length=25,frame_shift=10,sample_frequency=16000,high_freq=8000,low_freq=0,window_type='hamming')\n",
        "        return spec\n",
        "\n",
        "    def copy_paste(self, emo_wav, neutral_wav):\n",
        "        # Concatenate an emotional utterance and a neutral utterance\n",
        "        augmented_wav = torch.cat((emo_wav, neutral_wav), dim=-1)  # Concatenate along the time dimension\n",
        "        return augmented_wav\n",
        "\n",
        "    def apply_augmentations(self, wav, sample_rate): #added\n",
        "        # Convert PyTorch tensor to numpy for augmentation\n",
        "        wav_numpy = wav.numpy().flatten()\n",
        "\n",
        "        # Apply augmentations\n",
        "        augmented_wav = augment(samples=wav_numpy, sample_rate=sample_rate)\n",
        "\n",
        "        # Convert back to PyTorch tensor\n",
        "        wav = torch.tensor(augmented_wav).unsqueeze(0)\n",
        "\n",
        "        return wav\n",
        "    def __len__(self):\n",
        "        return len(self.data_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        wav, sample_rate = torchaudio.load(os.path.join(self.get_audio_dir_path, self.data_info.filename[idx]) + '.wav')\n",
        "         # Apply augmentations if in training mode\n",
        "        if self.mode == 'train':\n",
        "            # Applies GaussianNoise, PitchShift, TimeStretch, ClippingDistorition, and Gain augments\n",
        "            wav = self.apply_augmentations(wav, sample_rate)\n",
        "            # Combines emotional and neutral file to create a new sample\n",
        "            if np.random.rand() < 0.5:\n",
        "                # Index(['A', 'H', 'N', 'S'], dtype='object')\n",
        "                neutral_idx = np.random.choice(np.where(self.label == 2)[0])\n",
        "                neutral_wav, _ = torchaudio.load(os.path.join(self.get_audio_dir_path, self.data_info.filename[neutral_idx]) + '.wav')\n",
        "                wav = self.copy_paste(wav, neutral_wav)\n",
        "\n",
        "\n",
        "        wav = self.pre_process(wav)\n",
        "        spec = self.transform(self.extract_fbank(wav, sample_rate)).float()\n",
        "        label = torch.tensor(self.label[idx], dtype=torch.long)\n",
        "\n",
        "        return spec, label, self.data_info.filename[idx]\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Mymodel(nn.Module):\n",
        "    def __init__(self, feature_size=80, h_dims=256, emotion_cls=4):\n",
        "        super(Mymodel, self).__init__()\n",
        "        self.bn0 = nn.BatchNorm2d(feature_size)\n",
        "\n",
        "        self.conv_block1 = self.ConvBlock5x5(in_channels=3, out_channels=64)\n",
        "        self.conv_block2 = self.ConvBlock5x5(in_channels=64, out_channels=128)\n",
        "        self.conv_block3 = self.ConvBlock5x5(in_channels=128, out_channels=256)\n",
        "        self.conv_block4 = self.ConvBlock5x5(in_channels=256, out_channels=512)\n",
        "\n",
        "        self.att_block = self.AttBlock(512, h_dims, activation='linear')\n",
        "\n",
        "        self.fc1 = nn.Linear(h_dims, h_dims // 2)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.5) #previously it was 0.3\n",
        "        self.bn = nn.BatchNorm1d(h_dims // 2)\n",
        "        self.fc2 = nn.Linear(h_dims // 2, emotion_cls)\n",
        "        self.outlayer = nn.LogSoftmax(dim=-1)\n",
        "\n",
        "    class AttBlock(nn.Module):\n",
        "        def __init__(self, n_in, n_out, activation='linear', temperature=1.):\n",
        "            super(Mymodel.AttBlock, self).__init__()\n",
        "\n",
        "            self.activation = activation\n",
        "            self.temperature = temperature\n",
        "            self.att = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "            self.cla = nn.Conv1d(in_channels=n_in, out_channels=n_out, kernel_size=1, stride=1, padding=0, bias=True)\n",
        "\n",
        "            self.bn_att = nn.BatchNorm1d(n_out)\n",
        "\n",
        "        def forward(self, x):\n",
        "            norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
        "            cla = self.nonlinear_transform(self.cla(x))\n",
        "            x = torch.sum(norm_att * cla, dim=2)\n",
        "            return x, norm_att, cla\n",
        "\n",
        "        def nonlinear_transform(self, x):\n",
        "            if self.activation == 'linear':\n",
        "                return x\n",
        "            elif self.activation == 'sigmoid':\n",
        "                return torch.sigmoid(x)\n",
        "\n",
        "    class ConvBlock5x5(nn.Module):\n",
        "        def __init__(self, in_channels, out_channels):\n",
        "            super(Mymodel.ConvBlock5x5, self).__init__()\n",
        "            self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
        "                                   out_channels=out_channels,\n",
        "                                   kernel_size=(3, 3), stride=(1, 1), #Kernel_size previously is 5 , 5\n",
        "                                   padding=(1, 1), bias=False) #padding was pewviously 2, 2. Network in a Network Approach\n",
        "            self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
        "            x = input\n",
        "            x = F.relu_(self.bn1(self.conv1(x)))\n",
        "            if pool_type == 'max':\n",
        "                x = F.max_pool2d(x, kernel_size=pool_size)\n",
        "            elif pool_type == 'avg':\n",
        "                x = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "            elif pool_type == 'avg+max':\n",
        "                x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
        "                x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
        "                x = x1 + x2\n",
        "            else:\n",
        "                raise Exception('Incorrect argument!')\n",
        "            return x\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs.transpose(1, 3)\n",
        "        x = self.bn0(x)\n",
        "        x = x.transpose(1, 3)\n",
        "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='max')\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='max')\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='max')\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='max')\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "\n",
        "        x = torch.mean(x, dim=3)  # (batch_size, channels, time)\n",
        "        #att_output, norm_att, cla = self.att_block(x) #\n",
        "        x = torch.sum(x, dim=2)\n",
        "        emo_ebd = x\n",
        "        x = self.dropout(self.activation(self.bn(self.fc1(x))))\n",
        "        pred = self.outlayer(self.fc2(x))\n",
        "\n",
        "        return pred, emo_ebd\n",
        "\n",
        "# Setup environment and arguments\n",
        "seed = 2024 # random seed\n",
        "batch_size = 128  # batch size, reduce batch size, if you get out of memory problem\n",
        "epochs = 65  # the number of training epoch I reduced to 65 but original is 100. This is done as the curent method is unlikely to reach 100\n",
        "max_len = 6 # the input length for training\n",
        "lr = 1e-3  # learning rate originally 1e-3 will adjust once more variables are fine tuned\n",
        "loss_type = 'CE' #loss function\n",
        "optimizer_type = 'Adam' # optimizer, can try Adam or others\n",
        "\n",
        "def get_logger(filename, verbosity=1, name=None):\n",
        "    level_dict = {0: logging.DEBUG, 1: logging.INFO, 2: logging.WARNING}\n",
        "    formatter = logging.Formatter(\"[%(asctime)s][%(filename)s][line:%(lineno)d][%(levelname)s] %(message)s\")\n",
        "    logger = logging.getLogger(name)\n",
        "    logger.setLevel(level_dict[verbosity])\n",
        "\n",
        "    fh = logging.FileHandler(filename, \"w\")\n",
        "    fh.setFormatter(formatter)\n",
        "    logger.addHandler(fh)\n",
        "\n",
        "    sh = logging.StreamHandler()\n",
        "    sh.setFormatter(formatter)\n",
        "    logger.addHandler(sh)\n",
        "\n",
        "    return logger\n",
        "\n",
        "def train(model, device, train_loader, criterion, optimizer, epoch, logger):\n",
        "    model.train()\n",
        "    logger.info('start training')\n",
        "\n",
        "    lr = optimizer.param_groups[0][\"lr\"]\n",
        "    logger.info('lr: {:.5f}'.format(lr))\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    for batch, data in tqdm(enumerate(train_loader)):\n",
        "        spec, emo_label,_ = data\n",
        "        spec, emo_label = spec.to(device), emo_label.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        emo_output,_ = model(spec)\n",
        "        loss = criterion(emo_output, emo_label)\n",
        "\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_([param for param in model.parameters() if param.requires_grad], max_norm=10, norm_type=2)\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = emo_output.argmax(dim=1, keepdim=True)\n",
        "        correct += pred.eq(emo_label.view_as(pred)).sum().item()\n",
        "\n",
        "        if batch % 20 == 0:\n",
        "            logger.info('Epoch: {} [{}/{} ({:.0f}%)]\\t loss={:.5f}\\t '.format(epoch , batch * len(emo_label), len(train_loader.dataset), 100. * batch / len(train_loader), loss.item()))\n",
        "\n",
        "    logger.info('Train set Accuracy: {}/{} ({:.3f}%)'.format(correct, len(train_loader.dataset), 100. * correct / (len(train_loader.dataset))))\n",
        "    logger.info('finish training!')\n",
        "    return loss\n",
        "\n",
        "import pandas as pd\n",
        "def test(model, device, dataset_type, val_loader, criterion, logger, target_names):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    logger.info('testing on {}'.format(dataset_type))\n",
        "\n",
        "    pred_all = np.array([],dtype=np.int64)\n",
        "    true_all = np.array([],dtype=np.int64)\n",
        "    nameIDs = np.array([],dtype=str)\n",
        "\n",
        "    embs_all = []  # Collect all embeddings\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for spec, label, nameID in tqdm(val_loader):\n",
        "            #spec, label = [x.to(device) for x in spec], label.to(device)\n",
        "            spec, label = spec.to(device), label.to(device)\n",
        "            output,embs = model(spec)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
        "\n",
        "            pred = output.data.max(1)[1].cpu().numpy()\n",
        "            true = label.data.cpu().numpy()\n",
        "            pred_all = np.append(pred_all,pred)\n",
        "            true_all = np.append(true_all,true)\n",
        "            nameIDs = np.append(nameIDs,nameID)\n",
        "\n",
        "            embs_all.append(embs.cpu().numpy())  # Collect embeddings\n",
        "\n",
        "    test_loss /= len(val_loader.dataset)\n",
        "    acc = 100. * correct / len(val_loader.dataset)\n",
        "\n",
        "    logger.info('{}: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(dataset_type,\n",
        "        test_loss, correct, len(val_loader.dataset), acc))\n",
        "\n",
        "    if dataset_type == 'test':\n",
        "      con_mat = confusion_matrix(true_all,pred_all)\n",
        "      cls_rpt = classification_report(true_all,pred_all,target_names=target_names,digits=3)\n",
        "      logger.info('Confusion Matrix:\\n{}\\n'.format(con_mat))\n",
        "      logger.info('Classification Report:\\n{}\\n'.format(cls_rpt))\n",
        "      # Check if lengths match\n",
        "      if len(nameIDs) == len(pred_all):\n",
        "          # Create DataFrame with the combined data\n",
        "          df = pd.DataFrame({\n",
        "              'ID': nameIDs,\n",
        "              'Predict': pred_all,\n",
        "          })\n",
        "\n",
        "          # Save DataFrame to a CSV file\n",
        "          df.to_csv('label.csv', index=False)\n",
        "          print(\"Data successfully saved to label.csv, please submit label.csv to Kaggle to see the ranking if the testUA > 0.5453.\")\n",
        "      else:\n",
        "          print(f\"Length mismatch: nameIDs length is {len(nameIDs)}, pred_all length is {len(pred_all)}\")\n",
        "      #np.savez('results.npz', true_all=true_all, pred_all=pred_all)\n",
        "\n",
        "\n",
        "    UA = recall_score(true_all,pred_all,average='macro')\n",
        "    WA = recall_score(true_all,pred_all,average='weighted')\n",
        "\n",
        "\n",
        "    # Concatenate all embeddings\n",
        "    embs_all = np.concatenate(embs_all, axis=0)\n",
        "\n",
        "    return test_loss,UA,WA, embs_all, true_all\n",
        "\n",
        "def early_stopping(network,savepath,metricsInEpochs,gap):\n",
        "    best_metric_inx=np.argmax(metricsInEpochs)\n",
        "    if best_metric_inx+1==len(metricsInEpochs):\n",
        "        best = os.path.join(savepath, 'best_epoch_{}.pt'.format(best_metric_inx+1))\n",
        "        torch.save(network,best)\n",
        "        return False\n",
        "    elif (len(metricsInEpochs)-best_metric_inx >= gap):\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "savedir = 'exp'\n",
        "setup_seed(seed)\n",
        "stamp = datetime.datetime.now().strftime('%y%m%d%H%M')\n",
        "tag = stamp + '_' + str(epochs)\n",
        "try:\n",
        "    os.makedirs(savedir)\n",
        "except OSError:\n",
        "    if not os.path.isdir(savedir):\n",
        "        raise\n",
        "\n",
        "logpath = savedir + \"/exp.log\"\n",
        "modelpath = savedir + \"/model.pt\"\n",
        "\n",
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "train_set = Mydataset(mode='train', max_len=max_len,  seed=seed)\n",
        "val_set = Mydataset( mode='val', max_len=max_len, seed=seed)\n",
        "test_set = Mydataset( mode='test', max_len=max_len, seed=seed)\n",
        "\n",
        "drop_last = True if len(train_set)%batch_size<2 else False\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True, drop_last=drop_last)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=1, pin_memory=True)\n",
        "\n",
        "#print(f\"Number of batches in the train_loader: {len(train_loader)}\")\n",
        "#print(f\"Number of samples in the train_dataset: {len(train_dataset)}\")\n",
        "\n",
        "# Set the device to CPU (Maybe dont use it for final output as it takes 1hour per epoch. Best used to debug the code before it starts the epoch cycle)\n",
        "#device = torch.device('cpu')\n",
        "\n",
        "# Initialize the model on CPU\n",
        "model = Mymodel(feature_size=80, h_dims=512, emotion_cls=train_set.NumClasses).to(device)\n",
        "\n",
        "# If you need to load a saved model, ensure it loads to the CPU\n",
        "# model = torch.load('exp/model.pt', map_location=torch.device('cpu')) (dont uncomment prob not needed rn)\n",
        "\n",
        "# Criterion\n",
        "if loss_type == 'CE':\n",
        "    criterion = nn.NLLLoss()\n",
        "    criterion_test = nn.NLLLoss(reduction='sum')\n",
        "else:\n",
        "    raise NameError\n",
        "\n",
        "# Optimizer\n",
        "if optimizer_type == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=1e-5)\n",
        "elif optimizer_type == 'Adam':\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "else:\n",
        "    raise NameError\n",
        "\n",
        "# Logger\n",
        "logger = get_logger(logpath)\n",
        "\n",
        "# Scheduler\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', patience=15, factor=0.1, verbose=True)\n",
        "\n",
        "val_UA_list = []\n",
        "test_UA_dic = {}\n",
        "test_WA_dic = {}\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(1, epochs+1):\n",
        "    print(\"\\n\\n\")\n",
        "    start = time.time()\n",
        "    train_loss = train(model, device, train_loader, criterion, optimizer, epoch, logger)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    time.sleep(0.003)\n",
        "    val_loss,val_UA,_,_,_= test(model, device, 'val', val_loader, criterion_test, logger, train_set.ClassNames)\n",
        "    val_losses.append(val_loss)\n",
        "    end = time.time()\n",
        "    duration = end-start\n",
        "    val_UA_list.append(val_UA)\n",
        "    if early_stopping(model,savedir,val_UA_list,gap=20):\n",
        "        print('val loss has not been decreased for . epochs, stop training \\n')\n",
        "        break\n",
        "\n",
        "    scheduler.step(val_UA)\n",
        "    logger.info(\"-\"*50)\n",
        "    logger.info('EPOCH {:2d} | TIME {:5.4f} sec | Valid Loss {:5.4f} '.format(epoch, duration, val_loss))\n",
        "    logger.info(\"-\"*50)\n",
        "    time.sleep(0.003)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "45mGnIZlG9Ck"
      },
      "id": "45mGnIZlG9Ck",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attempted dual model approach\n",
        "This tried to incoperate an ASR to help train the SER model with the Multi Task learning layer to combine but due to the complexity and time constraint we never finished this build. Its here to show we attempted it. The paper that I was inspired to do this is in the following [Paper link](https://www.isca-archive.org/interspeech_2021/cai21b_interspeech.pdf)"
      ],
      "metadata": {
        "id": "byNr70ZtG79j"
      },
      "id": "byNr70ZtG79j"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Insert the SER+ASR Model code here\n",
        "import os\n",
        "import pandas as pd\n",
        "import torchaudio\n",
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import EarlyStoppingCallback\n",
        "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2ForSequenceClassification, Wav2Vec2ForCTC, Wav2Vec2Processor, Trainer, TrainingArguments\n",
        "import numpy as np\n",
        "\n",
        "# Path to your dataset and CSV file\n",
        "TSV = r'C:\\Users\\azree\\Downloads\\AAI3001_Project\\labels\\IEMOCAP_4.tsv'\n",
        "DATASET = r'C:\\Users\\azree\\Downloads\\AAI3001_Project\\dataset'\n",
        "TRAIN = os.path.join(DATASET, 'train')\n",
        "TEST = os.path.join(DATASET, 'test')\n",
        "VAL = os.path.join(DATASET, 'val')\n",
        "\n",
        "# Verify filepaths\n",
        "print(\"Train folder path:\", TRAIN)\n",
        "print(\"Test folder path:\", TEST)\n",
        "print(\"Validation folder path:\", VAL)\n",
        "\n",
        "# Define label mapping\n",
        "label_mapping = {\"A\": 0, \"H\": 1, \"N\": 2, \"S\": 3}\n",
        "\n",
        "# Parameters\n",
        "max_len = 6\n",
        "epochs = 5\n",
        "learning_rate = 5e-5\n",
        "weight_decay = 0.1\n",
        "batch_size = 16\n",
        "gradient_accumulation_steps = 2\n",
        "warmup_steps = 500\n",
        "\n",
        "# Load Wav2Vec2 Processor and ASR Model for Transcription\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "asr_model = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "\n",
        "# Load Wav2Vec2 Feature Extractor and Model for Emotion Recognition\n",
        "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(\"facebook/wav2vec2-large-960h\")\n",
        "model = Wav2Vec2ForSequenceClassification.from_pretrained(\"facebook/wav2vec2-large-960h\", num_labels=4)\n",
        "\n",
        "# Data Augmentation\n",
        "from audiomentations import Compose, AddGaussianNoise, PitchShift, TimeStretch, ClippingDistortion\n",
        "\n",
        "augment = Compose([\n",
        "    # This augmentation adds Gaussian noise to the audio signal.\n",
        "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
        "    # This augmentation changes the pitch of the audio signal by shifting it up or down by a random number of semitones within the specified range.\n",
        "    PitchShift(min_semitones=-4, max_semitones=4, p=0.5),\n",
        "    # This augmentation changes the tempo of the audio signal by stretching or compressing it.\n",
        "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
        "    # This augmentation simulates clipping distortion by applying a random threshold (in percentile) to the audio signal\n",
        "    ClippingDistortion(min_percentile_threshold=0, max_percentile_threshold=10, p=0.4)\n",
        "])\n",
        "\n",
        "def load_dataset_with_transcriptions(audio_folder, label_df):\n",
        "    data = []\n",
        "    for index, row in label_df.iterrows():\n",
        "        file_name = row[\"filename\"] + \".wav\"\n",
        "        label_str = row[\"label\"]\n",
        "        file_path = os.path.join(audio_folder, file_name)\n",
        "\n",
        "        if os.path.exists(file_path) and file_path.endswith(\".wav\"):\n",
        "            speech, sampling_rate = load_audio_file(file_path)\n",
        "            if speech is not None:\n",
        "                # Pad/Truncate audio to fixed length\n",
        "                speech = torch.tensor(speech).unsqueeze(0)\n",
        "                speech = pad_trunc_wav(speech, max_len=max_len).squeeze(0)\n",
        "\n",
        "                # Apply data augmentation\n",
        "                augmented_speech = augment(speech.numpy(), sampling_rate=sampling_rate)\n",
        "                augmented_speech = torch.tensor(augmented_speech).unsqueeze(0)\n",
        "                augmented_speech = pad_trunc_wav(augmented_speech, max_len=max_len).squeeze(0)\n",
        "\n",
        "                # Transcribe audio (ASR)\n",
        "                transcription = transcribe_audio(speech.numpy())\n",
        "                print(f\"Transcription: {transcription}\")\n",
        "\n",
        "                # Map label to integer\n",
        "                if label_str in label_mapping:\n",
        "                    label = label_mapping[label_str]\n",
        "                else:\n",
        "                    raise ValueError(f\"Unknown label '{label_str}' encountered.\")\n",
        "\n",
        "                # Append to dataset\n",
        "                data.append({\"speech\": speech, \"augmented_speech\": augmented_speech, \"transcription\": transcription, \"label\": label})\n",
        "    return Dataset.from_dict({\n",
        "        \"speech\": [d[\"speech\"] for d in data],\n",
        "        \"augmented_speech\": [d[\"augmented_speech\"] for d in data],\n",
        "        \"transcription\": [d[\"transcription\"] for d in data],\n",
        "        \"label\": [d[\"label\"] for d in data]\n",
        "    })\n",
        "\n",
        "# Define Dataset\n",
        "emotion_dataset = load_dataset_with_transcriptions(TRAIN, pd.read_csv(TSV))\n",
        "\n",
        "# Preprocessing Function\n",
        "def preprocess_function(examples):\n",
        "    inputs = feature_extractor(examples[\"speech\"], sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
        "    return inputs\n",
        "\n",
        "emotion_dataset = emotion_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Define Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./wav2vec2-test-results\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    learning_rate=learning_rate,\n",
        "    weight_decay=weight_decay,\n",
        "    warmup_steps=warmup_steps,\n",
        "    num_train_epochs=epochs,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=True,\n",
        "    optimizer=\"adamw\"\n",
        ")\n",
        "\n",
        "# Metric Computation Function\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    accuracy = np.mean(preds == labels)\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "# Trainer Object\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=emotion_dataset,\n",
        "    eval_dataset=emotion_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        ")\n",
        "\n",
        "# Train Model (SER)\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate Model (SER)\n",
        "eval_results = trainer.evaluate(emotion_dataset)\n",
        "print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "# Save Trained Model\n",
        "trainer.save_model(\"./wav2vec2-trained-model\")\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "w2nkqBM6mhGn"
      },
      "execution_count": null,
      "outputs": [],
      "id": "w2nkqBM6mhGn"
    }
  ]
}